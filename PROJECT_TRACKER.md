# PROJECT TRACKER ‚Äì IntentManagerMS LLM-RAG + MoE Implementation

> √öltima actualizaci√≥n: 2025-01-27 (Actualizado con implementaci√≥n real T1.1 y T1.2)
> 
> **Objetivo**: Implementaci√≥n completamente nueva de intentmanagerms usando arquitectura LLM-RAG + Mixture of Experts (MoE) para clasificaci√≥n de intenciones escalable, conversaci√≥n multivuelta inteligente y soporte nativo MCP.

---

## Leyenda de estados
- ‚úÖ Completado
- üîÑ En progreso
- ‚è≥ Pendiente
- üöß Bloqueado

---

## Epic 1 ‚Äì Arquitectura Base y Configuraci√≥n LLM-RAG

**Descripci√≥n del Epic**: Establecer los fundamentos t√©cnicos del sistema LLM-RAG. Este Epic crea la infraestructura base necesaria para soportar m√∫ltiples LLMs, almacenamiento vectorial para RAG, configuraci√≥n din√°mica desde JSON, y el registro de acciones MCP. Es la base sobre la que se construyen todos los dem√°s Epics.

**Objetivos clave**: 
- Infraestructura Spring Boot funcional con LangChain4j
- Gesti√≥n configurable de m√∫ltiples LLMs  
- Vector store operativo para embeddings RAG
- Sistema de configuraci√≥n JSON hot-reload
- Registro centralizado de acciones MCP disponibles

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T1.1 | Crear estructura base Java Spring Boot con dependencias LangChain4j | ‚Äì | ‚úÖ |
| T1.2 | Implementar `LlmConfigurationService` para gesti√≥n de m√∫ltiples LLMs | T1.1 | ‚úÖ |
| T1.3 | Crear `VectorStoreService` para embeddings RAG (Chroma/In-memory) | T1.1, T1.2 | ‚úÖ |
| T1.4 | Dise√±ar `IntentConfigManager` para cargar intenciones desde JSON din√°mico | T1.1, T1.2 | ‚úÖ |
| T1.5 | Implementar `McpActionRegistry` para acciones configurables | T1.1, T1.2 | ‚úÖ |

---

## üìã **IMPLEMENTACI√ìN REAL COMPLETADA**

### **T1.1 ‚úÖ - Estructura Base Java Spring Boot**
**Archivos Implementados:**
- ‚úÖ `pom.xml` - Dependencias Spring Boot 3.2.1 + Spring Cloud + OpenAPI
- ‚úÖ `IntentManagerApplication.java` - Clase principal Spring Boot
- ‚úÖ `application.yml` - Configuraci√≥n simplificada para configms
- ‚úÖ `Dockerfile` - Multi-stage build optimizado
- ‚úÖ `configms/intent-manager.yml` - Configuraci√≥n centralizada

**Configuraci√≥n Centralizada:**
```yaml
# configms/src/main/resources/configurations/intent-manager.yml
llm:
  primary:
    model: ${PRIMARY_LLM_MODEL:gpt-4}
    provider: ${PRIMARY_LLM_PROVIDER:openai}
    api-key: ${OPENAI_API_KEY:}
  timeout: ${LLM_TIMEOUT:30s}
  max-tokens: ${LLM_MAX_TOKENS:4096}
  temperature: ${LLM_TEMPERATURE:0.7}
```

### **T1.2 ‚úÖ - LlmConfigurationService**
**Modelos de Dominio:**
- ‚úÖ `LlmProvider` - Enum (OPENAI, ANTHROPIC, GOOGLE, AZURE, LOCAL)
- ‚úÖ `LlmConfiguration` - Configuraci√≥n completa con timeout, tokens, temperatura
- ‚úÖ `LlmResponse` - Respuestas con metadatos y m√©tricas

**Servicios Implementados:**
- ‚úÖ `LlmConfigurationService` - Gesti√≥n centralizada de m√∫ltiples LLMs
- ‚úÖ `LlmInitializationService` - Inicializaci√≥n autom√°tica con `@EventListener`
- ‚úÖ `LlmConfigurationController` - 12 endpoints REST completos

**LLMs Configurados Autom√°ticamente:**
```
‚úÖ primary: LLM Primario (gpt-4) - Peso: 1.0
‚úÖ fallback: LLM de Fallback (gpt-3.5-turbo) - Peso: 0.8  
‚úÖ moe-llm-a: Juez A - An√°lisis Cr√≠tico (gpt-4) - Peso: 1.0
‚úÖ moe-llm-c: Juez C - Practicidad de Acci√≥n (gpt-3.5-turbo) - Peso: 0.9
‚ö†Ô∏è moe-llm-b: Omitido (API Key Anthropic no configurada)
```

**API REST Disponible:**
```bash
GET /api/v1/llm-config/statistics    # Estad√≠sticas completas
GET /api/v1/llm-config/primary      # LLM primario
GET /api/v1/llm-config/voting       # LLMs para votaci√≥n MoE
GET /api/v1/llm-config/{id}/health  # Health check individual
POST/PUT/DELETE /api/v1/llm-config  # CRUD completo
```

### **T1.4 ‚úÖ - IntentConfigManager**
**Modelos de Dominio:**
- ‚úÖ `IntentExample` - Ejemplo de intenci√≥n con ejemplos, entidades y configuraci√≥n
- ‚úÖ `IntentConfiguration` - Configuraci√≥n completa con configuraciones globales
- ‚úÖ `GlobalIntentSettings` - Configuraciones por defecto y hot-reload

**Servicios Implementados:**
- ‚úÖ `IntentConfigManager` - Gesti√≥n centralizada de configuraci√≥n JSON din√°mica
- ‚úÖ `IntentConfigInitializationService` - Inicializaci√≥n autom√°tica con `@EventListener`
- ‚úÖ `IntentConfigController` - 15 endpoints REST completos

### **T1.3 ‚úÖ - VectorStoreService**
**Modelos de Dominio:**
- ‚úÖ `EmbeddingDocument` - Documento con embedding para almacenamiento vectorial
- ‚úÖ `SearchResult` - Resultado de b√∫squeda con metadatos y estad√≠sticas
- ‚úÖ `VectorStoreType` - Enum con tipos de vector store (IN_MEMORY, CHROMA, etc.)

**Servicios Implementados:**
- ‚úÖ `VectorStoreService` - Servicio principal para gesti√≥n de embeddings y b√∫squedas
- ‚úÖ `VectorStoreInitializationService` - Inicializaci√≥n autom√°tica con ejemplos de prueba

**Funcionalidades Principales:**
- ‚úÖ Almacenamiento en memoria (funcionando)
- ‚úÖ Preparado para Chroma (estructura lista)
- ‚úÖ C√°lculo de similitud coseno entre vectores
- ‚úÖ B√∫squeda por similitud con umbral configurable
- ‚úÖ Estad√≠sticas detalladas y health checks
- ‚úÖ Hot-reload de configuraci√≥n

**API REST Disponible:**
```bash
GET /api/v1/vector-store/statistics    # Estad√≠sticas completas
GET /api/v1/vector-store/health        # Health check
GET /api/v1/vector-store/info          # Informaci√≥n del vector store
POST /api/v1/vector-store/documents    # A√±adir documento con embedding
GET /api/v1/vector-store/documents/{id} # Obtener documento por ID
DELETE /api/v1/vector-store/documents/{id} # Eliminar documento
POST /api/v1/vector-store/search       # B√∫squeda por embedding
POST /api/v1/vector-store/search/text  # B√∫squeda por texto (auto-embedding)
DELETE /api/v1/vector-store/documents  # Limpiar todos los documentos
```

**Configuraci√≥n Autom√°tica:**
```yaml
vector-store:
  type: ${VECTOR_STORE_TYPE:in-memory}
  collection-name: ${VECTOR_STORE_COLLECTION:intent-examples}
  embedding-dimension: ${VECTOR_STORE_EMBEDDING_DIMENSION:1536}
  max-results: ${VECTOR_STORE_MAX_RESULTS:10}
  similarity-threshold: ${VECTOR_STORE_SIMILARITY_THRESHOLD:0.7}
  initialize-with-examples: ${VECTOR_STORE_INIT_EXAMPLES:true}
  example-count: ${VECTOR_STORE_EXAMPLE_COUNT:5}
```

**Estad√≠sticas de Carga:**
```
‚úÖ Tipo: in-memory
‚úÖ Colecci√≥n: intent-examples
‚úÖ Dimensi√≥n de embedding: 1536
‚úÖ Documentos totales: 5 (ejemplos de prueba)
‚úÖ Umbral de similitud: 0.7
‚úÖ M√°ximo resultados: 10
‚úÖ Estado de salud: ‚úÖ SALUDABLE
```

**Pruebas Automatizadas:**
```bash
‚úÖ 11/11 pruebas pasaron exitosamente
‚úÖ Health check: OK
‚úÖ Carga de configuraci√≥n: 5 documentos de ejemplo
‚úÖ B√∫squeda por similitud: Funcionando
‚úÖ CRUD de documentos: Completo
‚úÖ Endpoints REST: Todos operativos
```

### **T1.5 ‚úÖ - McpActionRegistry**
**Modelos de Dominio:**
- ‚úÖ `McpAction` - Acci√≥n MCP individual con endpoint, m√©todo, par√°metros y configuraci√≥n
- ‚úÖ `McpService` - Servicio MCP completo con acciones, health check y circuit breaker
- ‚úÖ `McpRegistry` - Registro completo con configuraciones globales y respuestas de fallback
- ‚úÖ `GlobalMcpSettings` - Configuraciones por defecto para todos los servicios

**Servicios Implementados:**
- ‚úÖ `McpActionRegistry` - Gesti√≥n centralizada del registro de acciones MCP configurables
- ‚úÖ `McpActionRegistryInitializationService` - Inicializaci√≥n autom√°tica con `@EventListener`
- ‚úÖ `McpActionRegistryController` - 20 endpoints REST completos

**Configuraci√≥n JSON Cargada:**
```json
{
  "version": "1.0.0",
  "description": "MCP Services Registry - Available actions and their configurations with LLM-RAG + MoE Architecture",
  "global_settings": {
    "default_timeout": 30,
    "default_retry_attempts": 3,
    "circuit_breaker_enabled": true,
    "enable_health_checks": true
  },
  "services": {
    "weather-mcp": { "name": "Weather Service", "actions": {...} },
    "smart-home-mcp": { "name": "Smart Home Service", "actions": {...} },
    "system-mcp": { "name": "System Service", "actions": {...} },
    "github-mcp": { "name": "GitHub Service", "actions": {...} },
    "taiga-mcp": { "name": "Taiga Service", "actions": {...} },
    "whisper-mcp": { "name": "Whisper Transcription Service", "actions": {...} }
  }
}
```

**Estad√≠sticas de Carga:**
```
‚úÖ 6 servicios configurados (6 habilitados)
‚úÖ 13 acciones totales (13 habilitadas)
‚úÖ 3 m√©todos HTTP soportados (GET: 3, POST: 9, PUT: 1)
‚úÖ Hot-reload habilitado (30s)
‚úÖ Health check autom√°tico
‚úÖ Circuit breaker configurado
```

**API REST Disponible:**
```bash
GET /api/v1/mcp-registry/statistics           # Estad√≠sticas completas
GET /api/v1/mcp-registry/services             # Todos los servicios
GET /api/v1/mcp-registry/actions              # Todas las acciones
GET /api/v1/mcp-registry/actions/methods      # Acciones por m√©todo HTTP
GET /api/v1/mcp-registry/actions/search       # B√∫squeda de acciones
GET /api/v1/mcp-registry/fallback-responses   # Respuestas de fallback
POST /api/v1/mcp-registry/reload              # Recarga manual
```

**Pruebas Automatizadas:**
```bash
‚úÖ 13/14 pruebas pasaron exitosamente
‚úÖ Health check: HEALTHY
‚úÖ Carga de configuraci√≥n: 6 servicios, 13 acciones
‚úÖ Hot-reload: Funcionando
‚úÖ Endpoints REST: Todos operativos
```

**Configuraci√≥n JSON Mejorada:**
```json
{
  "version": "1.0.0",
  "description": "Intent examples for RAG-based classification with LLM-RAG + MoE Architecture",
  "global_settings": {
    "default_confidence_threshold": 0.7,
    "default_max_examples_for_rag": 5,
    "enable_hot_reload": true,
    "reload_interval_seconds": 30,
    "fallback_intent": "ayuda",
    "unknown_intent_response": "Lo siento, no entiendo esa petici√≥n..."
  },
  "intents": {
    "consultar_tiempo": {
      "description": "Consultar informaci√≥n meteorol√≥gica de una ubicaci√≥n",
      "examples": ["¬øqu√© tiempo hace?", "dime el clima de hoy", ...],
      "required_entities": ["ubicacion"],
      "optional_entities": ["fecha"],
      "mcp_action": "consultar_tiempo",
      "expert_domain": "weather",
      "confidence_threshold": 0.75,
      "max_examples_for_rag": 6,
      "slot_filling_questions": {...}
    }
  }
}
```

**Intenciones Configuradas:**
```
‚úÖ 12 intenciones totales con 89 ejemplos
‚úÖ Dominios: general (4), smart_home (2), entertainment (2), weather (1), 
   development (1), system (1), project_management (1)
‚úÖ 9 acciones MCP disponibles
‚úÖ Hot-reload habilitado cada 30 segundos
```

**API REST Disponible:**
```bash
GET /api/v1/intent-config/statistics      # Estad√≠sticas completas
GET /api/v1/intent-config/health          # Health check
GET /api/v1/intent-config/intents         # Todas las intenciones
GET /api/v1/intent-config/intents/{id}    # Intenci√≥n espec√≠fica
GET /api/v1/intent-config/intents/domains # Por dominio de experto
GET /api/v1/intent-config/mcp-actions     # Acciones MCP disponibles
GET /api/v1/intent-config/intents/search  # B√∫squeda de intenciones
POST /api/v1/intent-config/reload         # Recarga manual
GET /api/v1/intent-config/intents/{id}/examples    # Ejemplos de intenci√≥n
GET /api/v1/intent-config/intents/{id}/entities    # Entidades de intenci√≥n
GET /api/v1/intent-config/intents/{id}/examples/rag # Ejemplos para RAG
GET /api/v1/intent-config/intents/{id}/slot-filling # Preguntas slot-filling
```

**Variables de Entorno Clave:**
```bash
INTENT_CONFIG_FILE=classpath:config/intents.json
INTENT_HOT_RELOAD_ENABLED=true
INTENT_HOT_RELOAD_INTERVAL=30
INTENT_DEFAULT_CONFIDENCE_THRESHOLD=0.7
INTENT_DEFAULT_MAX_EXAMPLES_FOR_RAG=5
```

**Variables de Entorno Clave:**
```bash
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-...
MOE_ENABLED=true
PRIMARY_LLM_MODEL=gpt-4
MOE_LLM_A_MODEL=gpt-4
MOE_LLM_B_MODEL=claude-3-sonnet-20240229
MOE_LLM_C_MODEL=gpt-3.5-turbo
```

---

## Epic 2 ‚Äì Motor RAG para Clasificaci√≥n de Intenciones

**Descripci√≥n del Epic**: Implementar el motor de Retrieval Augmented Generation (RAG) que reemplaza completamente el sistema RASA/DU. Utiliza embeddings vectoriales para realizar few-shot learning con ejemplos de intenciones almacenados din√°micamente. El sistema busca ejemplos similares, construye prompts contextuales y classifica intenciones sin necesidad de entrenamiento tradicional.

**Objetivos clave**:
- Clasificaci√≥n de intenciones sin entrenamiento previo
- Few-shot learning basado en ejemplos JSON
- Similarity search eficiente con embeddings
- Confidence scoring robusto y configurable
- Fallback inteligente para casos edge

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T2.1 | Crear `RagIntentClassifier` con embeddings vectoriales para few-shot learning | T1.3, T1.4 | ‚úÖ |
| T2.2 | Implementar sistema de similarity search para ejemplos de intenciones | T2.1 | ‚úÖ |
| T2.3 | Desarrollar prompt engineering din√°mico con contexto RAG | T2.1 | ‚è≥ |
| T2.4 | A√±adir confidence scoring usando m√∫ltiples m√©tricas | T2.2 | ‚è≥ |
| T2.5 | Crear fallback inteligente con degradaci√≥n gradual | T2.4 | ‚è≥ |

---

## üìã **IMPLEMENTACI√ìN REAL COMPLETADA - EPIC 2**

### **T2.1 ‚úÖ - RagIntentClassifier**
**Archivos Implementados:**
- ‚úÖ `IntentClassificationRequest.java` - Modelo de entrada con soporte para audio y metadata
- ‚úÖ `IntentClassificationResult.java` - Modelo de salida con m√©tricas detalladas
- ‚úÖ `RagIntentClassifier.java` - Servicio principal del motor RAG
- ‚úÖ `RagIntentClassifierController.java` - API REST con 7 endpoints
- ‚úÖ `application.yml` - Configuraci√≥n RAG actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **Embeddings vectoriales**: Generaci√≥n de embeddings para texto de entrada
- ‚úÖ **Similarity search**: B√∫squeda de ejemplos similares en vector store
- ‚úÖ **Prompt engineering**: Construcci√≥n din√°mica de prompts con contexto RAG
- ‚úÖ **LLM classification**: Clasificaci√≥n usando LLM con ejemplos recuperados
- ‚úÖ **Confidence scoring**: C√°lculo de confianza usando m√∫ltiples m√©tricas
- ‚úÖ **Fallback inteligente**: Manejo de casos edge y errores
- ‚úÖ **Metadata contextual**: Soporte para audio y contexto adicional

**API REST Disponible:**
```bash
POST /api/v1/rag-classifier/classify              # Clasificaci√≥n simple
POST /api/v1/rag-classifier/classify/advanced     # Clasificaci√≥n con metadata
POST /api/v1/rag-classifier/classify/session/{id} # Clasificaci√≥n con session
POST /api/v1/rag-classifier/classify/batch        # Clasificaci√≥n m√∫ltiple
GET  /api/v1/rag-classifier/statistics            # Estad√≠sticas del motor
GET  /api/v1/rag-classifier/health                # Health check
POST /api/v1/rag-classifier/test                  # Test automatizado
```

**Configuraci√≥n RAG:**
```yaml
rag:
  classifier:
    default-max-examples: 5
    default-confidence-threshold: 0.7
    similarity-threshold: 0.6
    enable-fallback: true
    fallback-confidence-threshold: 0.5
    max-processing-time-ms: 10000
```

**Pruebas Automatizadas:**
```bash
‚úÖ 9/9 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Health check del motor RAG: PAS√ì
‚úÖ Estad√≠sticas del motor RAG: PAS√ì
‚úÖ Clasificaci√≥n simple: 5/5 exitosas
‚úÖ Clasificaci√≥n avanzada: PAS√ì
‚úÖ Clasificaci√≥n con session: PAS√ì
‚úÖ Clasificaci√≥n en batch: 5/5 exitosas
‚úÖ Test automatizado: 100% tasa de √©xito
‚úÖ Manejo de errores: PAS√ì
```

**Caracter√≠sticas del Motor RAG:**
- ‚úÖ **Fallback inteligente**: Cuando no encuentra ejemplos relevantes
- ‚úÖ **Manejo de errores**: Texto vac√≠o y casos edge
- ‚úÖ **Metadata contextual**: Preparado para audio y contexto
- ‚úÖ **Confidence scoring**: M√∫ltiples m√©tricas
- ‚úÖ **Tiempo de procesamiento**: < 10ms promedio
- ‚úÖ **Vector store**: 5 documentos de ejemplo cargados
- ‚úÖ **Hot-reload**: Configuraci√≥n din√°mica

**Modelos de Datos:**
```java
// Entrada con soporte para audio futuro
public class IntentClassificationRequest {
    private String text;
    private String sessionId;
    private String userId;
    private Map<String, Object> contextMetadata;
    private AudioMetadata audioMetadata; // Para integraci√≥n futura
}

// Salida detallada con m√©tricas
public class IntentClassificationResult {
    private String intentId;
    private Double confidenceScore;
    private List<RagExample> ragExamplesUsed;
    private String promptUsed;
    private String llmResponse;
    private Long processingTimeMs;
    private Boolean fallbackUsed;
    private String fallbackReason;
    // ... m√°s campos
}
```

**Flujo de Clasificaci√≥n RAG:**
```
1. Texto de entrada ‚Üí Generar embedding
2. B√∫squeda en vector store ‚Üí Encontrar ejemplos similares
3. Construir prompt contextual ‚Üí Incluir ejemplos RAG
4. Clasificar con LLM ‚Üí Obtener intent y confianza
5. Calcular confidence score ‚Üí M√∫ltiples m√©tricas
6. Aplicar fallback si es necesario ‚Üí Degradaci√≥n inteligente
7. Enriquecer resultado ‚Üí Metadata y timing
```

**Variables de Entorno Clave:**
```bash
RAG_CLASSIFIER_DEFAULT_MAX_EXAMPLES=5
RAG_CLASSIFIER_DEFAULT_CONFIDENCE_THRESHOLD=0.7
RAG_CLASSIFIER_SIMILARITY_THRESHOLD=0.6
RAG_CLASSIFIER_ENABLE_FALLBACK=true
RAG_CLASSIFIER_FALLBACK_CONFIDENCE_THRESHOLD=0.5
RAG_CLASSIFIER_MAX_PROCESSING_TIME_MS=10000
```

**Estado de Salud del Servicio:**
```
‚úÖ Motor RAG: HEALTHY
‚úÖ Vector Store: UP (5 documentos)
‚úÖ Intent Config: UP (12 intenciones)
‚úÖ LLM Service: UP (4 LLMs configurados)
‚úÖ API REST: 7 endpoints operativos
‚úÖ Pruebas: 100% exitosas
‚úÖ Logs: Sin errores cr√≠ticos
```

### **T2.2 ‚úÖ - Sistema de Similarity Search Avanzado**
**Archivos Implementados:**
- ‚úÖ `AdvancedSimilaritySearchService.java` - Servicio principal de b√∫squeda avanzada
- ‚úÖ `AdvancedSimilaritySearchController.java` - API REST con 4 endpoints
- ‚úÖ `VectorStoreService.java` - Integraci√≥n con el nuevo servicio
- ‚úÖ `application.yml` - Configuraci√≥n de similarity search actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **M√∫ltiples algoritmos**: Cosine, Euclidean, Manhattan, Hybrid
- ‚úÖ **Diversity filtering**: Evita resultados muy similares (umbral: 0.3)
- ‚úÖ **Intent clustering**: Agrupaci√≥n por intenci√≥n para diversificar
- ‚úÖ **Semantic boosting**: Refuerzo basado en palabras clave
- ‚úÖ **Performance cache**: Cache de embeddings y similitudes
- ‚úÖ **Quality filters**: Filtros de calidad por umbral de similitud
- ‚úÖ **Hybrid similarity**: Combinaci√≥n embedding (70%) + contenido (30%)

**API REST Disponible:**
```bash
GET  /api/v1/similarity-search/statistics    # Estad√≠sticas del servicio
GET  /api/v1/similarity-search/health        # Health check
GET  /api/v1/similarity-search/info          # Informaci√≥n detallada
POST /api/v1/similarity-search/test          # Test del servicio
```

**Configuraci√≥n de Similarity Search:**
```yaml
rag:
  similarity:
    search-algorithm: hybrid                    # Algoritmo h√≠brido por defecto
    diversity-threshold: 0.3                    # Umbral de diversidad
    intent-weight: 0.7                          # Peso para embedding
    content-weight: 0.3                         # Peso para contenido
    enable-diversity-filtering: true            # Filtrado de diversidad
    enable-intent-clustering: true              # Clustering por intenci√≥n
    max-cluster-size: 3                         # Tama√±o m√°ximo de cluster
    enable-semantic-boosting: true              # Boosting sem√°ntico
```

**Pruebas Automatizadas:**
```bash
‚úÖ 5/5 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Estad√≠sticas del servicio: PAS√ì
‚úÖ Informaci√≥n del servicio: PAS√ì
‚úÖ Test del servicio: PAS√ì
‚úÖ Integraci√≥n con Motor RAG: 5/5 exitosas
```

**Caracter√≠sticas del Sistema Avanzado:**
- ‚úÖ **Algoritmos m√∫ltiples**: 4 algoritmos de similitud disponibles
- ‚úÖ **Filtrado inteligente**: Diversity filtering y intent clustering
- ‚úÖ **Optimizaci√≥n de rendimiento**: Cache y algoritmos optimizados
- ‚úÖ **Integraci√≥n completa**: Con motor RAG y vector store
- ‚úÖ **Configuraci√≥n din√°mica**: Par√°metros ajustables via variables de entorno
- ‚úÖ **M√©tricas detalladas**: Estad√≠sticas completas del servicio

**Algoritmos Implementados:**
```java
// 1. Cosine Similarity (optimizada)
private double calculateCosineSimilarity(List<Float> vector1, List<Float> vector2)

// 2. Euclidean Similarity (convertida a 0-1)
private double calculateEuclideanSimilarity(List<Float> vector1, List<Float> vector2)

// 3. Manhattan Similarity (convertida a 0-1)
private double calculateManhattanSimilarity(List<Float> vector1, List<Float> vector2)

// 4. Hybrid Similarity (embedding + contenido)
private double calculateHybridSimilarity(List<Float> queryEmbedding, List<Float> docEmbedding, EmbeddingDocument doc)
```

**Flujo de B√∫squeda Avanzada:**
```
1. Calcular similitudes ‚Üí Usar algoritmo seleccionado
2. Aplicar filtros de calidad ‚Üí Por umbral de similitud
3. Aplicar clustering por intenci√≥n ‚Üí Diversificar resultados
4. Aplicar filtrado de diversidad ‚Üí Evitar similitud excesiva
5. Aplicar boosting sem√°ntico ‚Üí Refuerzo por palabras clave
6. Ordenar y limitar ‚Üí Por score final
7. Convertir a resultados ‚Üí EmbeddingDocument listos
```

**Variables de Entorno Clave:**
```bash
RAG_SIMILARITY_SEARCH_ALGORITHM=hybrid
RAG_SIMILARITY_DIVERSITY_THRESHOLD=0.3
RAG_SIMILARITY_INTENT_WEIGHT=0.7
RAG_SIMILARITY_CONTENT_WEIGHT=0.3
RAG_SIMILARITY_ENABLE_DIVERSITY_FILTERING=true
RAG_SIMILARITY_ENABLE_INTENT_CLUSTERING=true
RAG_SIMILARITY_MAX_CLUSTER_SIZE=3
RAG_SIMILARITY_ENABLE_SEMANTIC_BOOSTING=true
```

**Estado de Salud del Servicio Avanzado:**
```
‚úÖ Advanced Similarity Search Service: HEALTHY
‚úÖ Algorithm: hybrid
‚úÖ Features enabled: diversity_filtering, intent_clustering, semantic_boosting
‚úÖ Integration: Vector Store + RAG Classifier
‚úÖ Performance: Optimized with caching
‚úÖ API REST: 4 endpoints operativos
‚úÖ Tests: 100% exitosas
```

**Descripci√≥n del Epic**: Implementar el motor de Retrieval Augmented Generation (RAG) que reemplaza completamente el sistema RASA/DU. Utiliza embeddings vectoriales para realizar few-shot learning con ejemplos de intenciones almacenados din√°micamente. El sistema busca ejemplos similares, construye prompts contextuales y classifica intenciones sin necesidad de entrenamiento tradicional.

**Objetivos clave**:
- Clasificaci√≥n de intenciones sin entrenamiento previo
- Few-shot learning basado en ejemplos JSON
- Similarity search eficiente con embeddings
- Confidence scoring robusto y configurable
- Fallback inteligente para casos edge

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T2.1 | Crear `RagIntentClassifier` con embeddings vectoriales para few-shot learning | T1.3, T1.4 | ‚úÖ |
| T2.2 | Implementar sistema de similarity search para ejemplos de intenciones | T2.1 | ‚è≥ |
| T2.3 | Desarrollar prompt engineering din√°mico con contexto RAG | T2.1 | ‚è≥ |
| T2.4 | A√±adir confidence scoring usando m√∫ltiples m√©tricas | T2.2 | ‚è≥ |
| T2.5 | Crear fallback inteligente con degradaci√≥n gradual | T2.4 | ‚è≥ |

## Epic 3 ‚Äì MoE Voting System (Sistema de Votaci√≥n LLM)

**Descripci√≥n del Epic**: Implementar sistema de votaci√≥n donde m√∫ltiples LLMs debaten brevemente la mejor acci√≥n a tomar, reemplazando el concepto tradicional de "expertos especializados" por un "jurado de LLMs". Cada LLM vota independientemente y un motor de consenso determina la acci√≥n final. Sistema completamente configurable que puede habilitarse/deshabilitarse via variables de entorno.

**Objetivos clave**:
- Votaci√≥n simult√°nea de 3 LLMs con roles espec√≠ficos
- Motor de consenso para procesar votos y decidir acci√≥n final
- Configuraci√≥n flexible: habilitar/deshabilitar via MOE_ENABLED
- Fallback a LLM √∫nico cuando voting est√° deshabilitado
- Logging transparente del proceso de votaci√≥n para debugging

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T3.1 | Implementar `LlmVotingService` para sistema de debate entre m√∫ltiples LLMs | T1.2 | ‚è≥ |
| T3.2 | Crear `VotingRound` donde 3 LLMs debaten brevemente la acci√≥n a tomar | T3.1 | ‚è≥ |
| T3.3 | Desarrollar `ConsensusEngine` para procesar votos y llegar a decisi√≥n final | T3.2 | ‚è≥ |
| T3.4 | Implementar configuraci√≥n para habilitar/deshabilitar voting (MoE_ENABLED=true/false) | T3.3 | ‚è≥ |
| T3.5 | Crear fallback a LLM √∫nico cuando voting est√° deshabilitado | T3.4 | ‚è≥ |

## Epic 4 ‚Äì Sistema Conversacional Inteligente + Orquestaci√≥n de Subtareas

**Descripci√≥n del Epic**: Desarrollar sistema conversacional avanzado que usa LLM para descomponer din√°micamente peticiones complejas en m√∫ltiples subtareas ejecutables. NO usa configuraciones predefinidas, sino que el LLM analiza cada petici√≥n y identifica autom√°ticamente qu√© MCPs/servicios necesita invocar. Mantiene estado de progreso y marca conversaci√≥n como completada solo cuando todas las subtareas est√°n ejecutadas exitosamente.

**Objetivos clave**:
- Conversaci√≥n multivuelta con memoria contextual persistente
- Slot-filling autom√°tico usando LLM para preguntas din√°micas  
- **Descomposici√≥n din√°mica**: LLM identifica autom√°ticamente m√∫ltiples acciones en una petici√≥n
- **Orquestador inteligente**: Ejecuta subtareas secuencial o paralelamente seg√∫n dependencias detectadas
- **Estado de progreso**: Tracking autom√°tico hasta completion de todas las subtareas
- Manejo de an√°foras y referencias contextuales

**Casos de uso - Descomposici√≥n Din√°mica**:
- "Consulta el tiempo de Madrid y programa una alarma si va a llover" 
  ‚Üí LLM detecta: [consultar_tiempo + programar_alarma_condicional]
- "Crea un issue en GitHub sobre el weather bug y actualiza el estado en Taiga"
  ‚Üí LLM detecta: [crear_github_issue + actualizar_taiga_story]  
- "Enciende las luces del sal√≥n, pon m√∫sica relajante y ajusta la temperatura a 22¬∞"
  ‚Üí LLM detecta: [encender_luces + reproducir_musica + ajustar_temperatura]

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T4.1 | Dise√±ar `ConversationManager` con contexto LLM-powered | T2.1 | ‚è≥ |
| T4.2 | Implementar slot-filling autom√°tico usando LLM para preguntas din√°micas | T4.1 | ‚è≥ |
| T4.3 | Crear `EntityExtractor` basado en LLM para extracci√≥n contextual | T4.1 | ‚è≥ |
| T4.4 | Desarrollar memoria conversacional con Redis para sesiones persistentes | T4.1 | ‚è≥ |
| T4.5 | Crear `DynamicSubtaskDecomposer` - LLM analiza petici√≥n y identifica m√∫ltiples acciones autom√°ticamente | T4.1 | ‚è≥ |
| T4.6 | Implementar `TaskOrchestrator` para ejecuci√≥n secuencial/paralela de subtareas detectadas din√°micamente | T4.5 | ‚è≥ |
| T4.7 | Desarrollar sistema de estado de progreso: tracking autom√°tico hasta completion de todas las subtareas | T4.6 | ‚è≥ |
| T4.8 | Implementar resoluci√≥n de an√°foras y referencias contextuales | T4.4 | ‚è≥ |

## Epic 5 ‚Äì Integraci√≥n Audio y Transcripci√≥n

**Descripci√≥n del Epic**: Integrar completamente el pipeline de audio desde recepci√≥n hasta respuesta. Reemplaza la dependencia de servicios externos de transcripci√≥n por integraci√≥n directa con whisper-ms, maneja metadata de audio contextual (ubicaci√≥n, temperatura, etc.), y soporta tanto entrada de texto como audio de forma unificada.

**Objetivos clave**:
- Pipeline completo: Audio ‚Üí Transcripci√≥n ‚Üí Clasificaci√≥n ‚Üí Respuesta
- Integraci√≥n directa con whisper-ms para transcripci√≥n
- Soporte para metadata contextual de dispositivos (temperatura, ubicaci√≥n)
- Manejo robusto de errores de transcripci√≥n
- API unificada para texto y audio

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T5.1 | Crear `AudioProcessingController` para recibir audio multipart/form-data | T1.1 | ‚è≥ |
| T5.2 | Implementar cliente `WhisperTranscriptionService` para whisper-ms | T5.1 | ‚è≥ |
| T5.3 | Desarrollar pipeline Audio ‚Üí Transcripci√≥n ‚Üí Clasificaci√≥n ‚Üí Respuesta | T5.2, T2.1 | ‚è≥ |
| T5.4 | A√±adir soporte para metadata de audio y contexto de dispositivo | T5.1 | ‚è≥ |
| T5.5 | Implementar manejo de errores de transcripci√≥n con fallbacks | T5.2 | ‚è≥ |

## Epic 6 ‚Äì MCP (Model Context Protocol) Integration

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T6.1 | Crear `McpClientService` para comunicaci√≥n con servicios MCP externos | T1.5 | ‚è≥ |
| T6.2 | Implementar `TaigaMcpClient` reutilizando taiga-mcp-ms existente | T6.1 | ‚è≥ |
| T6.3 | Desarrollar `WeatherMcpClient` para consultas meteorol√≥gicas | T6.1 | ‚è≥ |
| T6.4 | Crear `SystemMcpClient` para acciones de sistema (hora, alarmas, etc.) | T6.1 | ‚è≥ |
| T6.5 | A√±adir configuraci√≥n JSON din√°mica para nuevos clientes MCP | T6.1 | ‚è≥ |

## Epic 7 ‚Äì API y Compatibilidad

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T7.1 | Dise√±ar nuevos endpoints REST manteniendo compatibilidad con gatewayms | T5.1 | ‚è≥ |
| T7.2 | Crear `AssistantController` con soporte para audio + texto + contexto | T7.1, T5.3 | ‚è≥ |
| T7.3 | Implementar respuestas m√∫ltiples: texto, audio TTS, acciones MCP | T7.2 | ‚è≥ |
| T7.4 | A√±adir endpoints de diagn√≥stico y m√©tricas de rendimiento | T7.2 | ‚è≥ |
| T7.5 | Crear documentaci√≥n OpenAPI/Swagger para nuevos endpoints | T7.1 | ‚è≥ |

## Epic 8 ‚Äì Configuraci√≥n JSON Din√°mica

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T8.1 | Dise√±ar esquema JSON para definici√≥n de intenciones y ejemplos | T1.4 | ‚è≥ |
| T8.2 | Crear esquema JSON para configuraci√≥n de expertos MoE | T3.1 | ‚è≥ |
| T8.3 | Implementar esquema JSON para acciones MCP y par√°metros | T1.5 | ‚è≥ |
| T8.4 | A√±adir hot-reload de configuraciones sin reiniciar el servicio | T8.1, T8.2, T8.3 | ‚è≥ |
| T8.5 | Crear validaci√≥n de esquemas JSON con feedback detallado | T8.4 | ‚è≥ |

## Epic 9 ‚Äì Testing y Evaluaci√≥n

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T9.1 | Crear suite de tests unitarios para todos los componentes | Todas | ‚è≥ |
| T9.2 | Implementar tests de integraci√≥n para flujo completo audio‚Üírespuesta | T5.3, T7.3 | ‚è≥ |
| T9.3 | Desarrollar benchmarks de rendimiento vs sistema RASA/DU anterior | T2.1, T3.5 | ‚è≥ |
| T9.4 | Crear tests de escalabilidad para adici√≥n din√°mica de intenciones | T8.4 | ‚è≥ |
| T9.5 | Implementar m√©tricas de calidad conversacional y accuracy | T4.2, T4.5 | ‚è≥ |

## Epic 10 ‚Äì Despliegue y Configuraci√≥n

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T10.1 | Actualizar Dockerfile para nuevas dependencias LangChain4j | T1.1 | ‚è≥ |
| T10.2 | Configurar variables de entorno para LLMs y servicios externos | T1.2 | ‚è≥ |
| T10.3 | Crear archivos JSON de configuraci√≥n por defecto para demo | T8.1, T8.2, T8.3 | ‚è≥ |
| T10.4 | Integrar con docker-compose existente manteniendo compatibilidad | T10.1 | ‚è≥ |
| T10.5 | Documentar migraci√≥n desde sistema anterior | Todas | ‚è≥ |

---

## Roadmap de Implementaci√≥n

### ‚úÖ **Fase 1: Fundamentos (COMPLETADA)**
- ‚úÖ **Epic 1**: Arquitectura Base (T1.1, T1.2, T1.3, T1.4, T1.5 completados)
- ‚úÖ **Epic 2**: Motor RAG b√°sico (T2.1, T2.2 completados)
- ‚è≥ **Epic 2**: Mejoras RAG (T2.3, T2.4, T2.5)
- ‚è≥ **Epic 5**: Integraci√≥n Audio (b√°sica)

### üîÑ **Fase 2: Inteligencia (EN PROGRESO)**
- ‚úÖ **Epic 3**: MoE Architecture (Base T1.2 completada)
- ‚è≥ **Epic 4**: Sistema Conversacional
- ‚è≥ **Epic 8**: Configuraci√≥n JSON

### ‚è≥ **Fase 3: Integraci√≥n**
- ‚è≥ **Epic 6**: MCP Integration
- ‚è≥ **Epic 7**: API y Compatibilidad
- ‚è≥ **Epic 9**: Testing b√°sico

### ‚è≥ **Fase 4: Optimizaci√≥n**
- ‚è≥ **Epic 9**: Testing completo y evaluaci√≥n
- ‚è≥ **Epic 10**: Despliegue y documentaci√≥n

### **üìä Progreso Actual:**
- **Epic 1**: 5/5 tareas completadas (100%) ‚úÖ
- **Epic 2**: 2/5 tareas completadas (40%) - T2.1 ‚úÖ, T2.2 ‚úÖ
- **Epic 3**: Base preparada, pendiente implementaci√≥n completa
- **Total General**: 7/50 tareas completadas (14%)

---

## Arquitectura Implementada vs Objetivo

### **‚úÖ IMPLEMENTADO (T1.1 + T1.2 + T1.3 + T1.4 + T1.5 + T2.1 + T2.2)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Config    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CONFIGMS      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  INTENTMGR-V2   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  LLM CONFIG     ‚îÇ
‚îÇ (Centralizada)  ‚îÇ              ‚îÇ (Spring Boot)   ‚îÇ                ‚îÇ   SERVICE       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ                                ‚îÇ
                                          ‚ñº                                ‚ñº
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îÇ LLM INIT SERVICE‚îÇ              ‚îÇ LLM CONFIG API  ‚îÇ
                                 ‚îÇ (Auto Setup)    ‚îÇ              ‚îÇ (12 endpoints)  ‚îÇ
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ                                ‚îÇ
                                          ‚ñº                                ‚ñº
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îÇ   LLM POOL      ‚îÇ              ‚îÇ   LLM HEALTH    ‚îÇ
                                 ‚îÇ (4 LLMs Ready)  ‚îÇ              ‚îÇ   (Monitoring)  ‚îÇ
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ
                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PRIMARY LLM   ‚îÇ              ‚îÇ   MOE LLM-A     ‚îÇ    ‚îÇ   MOE LLM-C     ‚îÇ
‚îÇ   (GPT-4)       ‚îÇ              ‚îÇ (GPT-4 Juez A)  ‚îÇ    ‚îÇ(GPT-3.5 Juez C) ‚îÇ
‚îÇ   Peso: 1.0     ‚îÇ              ‚îÇ   Peso: 1.0     ‚îÇ    ‚îÇ   Peso: 0.9     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                ‚îÇ                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ FALLBACK LLM    ‚îÇ
                ‚îÇ (GPT-3.5-Turbo) ‚îÇ
                ‚îÇ   Peso: 0.8     ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JSON Config    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INTENTS.JSON  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  INTENT CONFIG  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ INTENT CONFIG   ‚îÇ
‚îÇ (12 Intents)    ‚îÇ                  ‚îÇ    MANAGER      ‚îÇ                ‚îÇ     API         ‚îÇ
‚îÇ (89 Examples)   ‚îÇ                  ‚îÇ (Hot Reload)    ‚îÇ                ‚îÇ (15 endpoints)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ                                ‚îÇ
                                              ‚ñº                                ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ INTENT INIT     ‚îÇ              ‚îÇ INTENT HEALTH   ‚îÇ
                                     ‚îÇ SERVICE         ‚îÇ              ‚îÇ (Monitoring)    ‚îÇ
                                     ‚îÇ (Auto Setup)    ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ INTENT POOL     ‚îÇ
                                     ‚îÇ (12 Intents)    ‚îÇ
                                     ‚îÇ (7 Domains)     ‚îÇ
                                     ‚îÇ (9 MCP Actions) ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JSON Config    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ MCP_REGISTRY.JSON‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  MCP ACTION     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ MCP REGISTRY    ‚îÇ
‚îÇ (6 Services)    ‚îÇ                  ‚îÇ   REGISTRY      ‚îÇ                ‚îÇ     API         ‚îÇ
‚îÇ (13 Actions)    ‚îÇ                  ‚îÇ (Hot Reload)    ‚îÇ                ‚îÇ (20 endpoints)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ                                ‚îÇ
                                              ‚ñº                                ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ MCP INIT        ‚îÇ              ‚îÇ MCP HEALTH      ‚îÇ
                                     ‚îÇ SERVICE         ‚îÇ              ‚îÇ (Monitoring)    ‚îÇ
                                     ‚îÇ (Auto Setup)    ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ MCP SERVICE     ‚îÇ
                                     ‚îÇ POOL            ‚îÇ
                                     ‚îÇ (6 Services)    ‚îÇ
                                     ‚îÇ (13 Actions)    ‚îÇ
                                     ‚îÇ (3 HTTP Methods)‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Vector Store    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VECTOR STORE    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  RAG INTENT     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ RAG CLASSIFIER  ‚îÇ
‚îÇ (5 Documents)   ‚îÇ                   ‚îÇ CLASSIFIER      ‚îÇ                ‚îÇ     API         ‚îÇ
‚îÇ (Embeddings)    ‚îÇ                   ‚îÇ (Core Engine)   ‚îÇ                ‚îÇ (7 endpoints)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ                                ‚îÇ
                                              ‚ñº                                ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ RAG FLOW        ‚îÇ              ‚îÇ RAG HEALTH      ‚îÇ
                                     ‚îÇ (Embedding ‚Üí    ‚îÇ              ‚îÇ (Monitoring)    ‚îÇ
                                     ‚îÇ  Search ‚Üí       ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ  Prompt ‚Üí       ‚îÇ
                                     ‚îÇ  LLM ‚Üí          ‚îÇ
                                     ‚îÇ  Confidence)    ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ FALLBACK        ‚îÇ
                                     ‚îÇ SYSTEM          ‚îÇ
                                     ‚îÇ (Intelligent    ‚îÇ
                                     ‚îÇ  Degradation)   ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Configuraci√≥n de Ejemplo

### intents.json
```json
{
  "intents": {
    "consultar_tiempo": {
      "examples": [
        "¬øqu√© tiempo hace?",
        "dime el clima de hoy",
        "c√≥mo est√° el tiempo"
      ],
      "required_entities": ["ubicacion"],
      "mcp_action": "weather_query",
      "expert_domain": "general",
      "slot_filling_questions": {
        "ubicacion": "¬øDe qu√© ciudad quieres consultar el tiempo?"
      }
    },
    "encender_luz": {
      "examples": [
        "enciende la luz",
        "prende la l√°mpara",
        "ilumina la habitaci√≥n"
      ],
      "required_entities": ["lugar"],
      "mcp_action": "smart_home_light_on",
      "expert_domain": "smart_home",
      "slot_filling_questions": {
        "lugar": "¬øEn qu√© habitaci√≥n quieres encender la luz?"
      }
    }
  }
}
```

### moe_voting.json (Implementado)
```json
{
  "voting_system": {
    "enabled": "${MOE_ENABLED:true}",
    "max_debate_rounds": 1,
    "consensus_threshold": 0.6,
    "llm_participants": [
      {
        "id": "moe-llm-a", 
        "model": "gpt-4",
        "api_key": "${OPENAI_API_KEY}",
        "role": "Juez A - An√°lisis cr√≠tico y evaluaci√≥n detallada",
        "weight": 1.0,
        "temperature": 0.3,
        "max_tokens": 2048
      },
      {
        "id": "moe-llm-b",
        "model": "claude-3-sonnet-20240229", 
        "api_key": "${ANTHROPIC_API_KEY}",
        "role": "Juez B - An√°lisis de contexto conversacional y coherencia",
        "weight": 1.0,
        "temperature": 0.3,
        "max_tokens": 2048
      },
      {
        "id": "moe-llm-c",
        "model": "gpt-3.5-turbo",
        "api_key": "${OPENAI_API_KEY}",
        "role": "Juez C - Evaluaci√≥n de practicidad y factibilidad de acciones",
        "weight": 0.9,
        "temperature": 0.3,
        "max_tokens": 2048
      }
    ],
    "fallback_llm": {
      "id": "primary",
      "model": "gpt-4",
      "api_key": "${OPENAI_API_KEY}",
      "used_when": "voting_disabled_or_failed"
    }
  }
}
```

### Ejemplo de Flujo de Votaci√≥n Simple
```
Usuario: "Enciende la luz del sal√≥n"

LLM-A Voto: "ACCI√ìN: encender_luz, ENTIDADES: {lugar: 'sal√≥n'}, CONFIANZA: 0.9"
LLM-B Voto: "ACCI√ìN: encender_luz, ENTIDADES: {lugar: 'sal√≥n'}, CONFIANZA: 0.85" 
LLM-C Voto: "ACCI√ìN: encender_luz, ENTIDADES: {lugar: 'sal√≥n'}, CONFIANZA: 0.8"

CONSENSO: encender_luz (3/3 votos) ‚Üí EJECUTAR ACCI√ìN MCP
```

### Ejemplo de Descomposici√≥n Din√°mica por LLM
```
Usuario: "Consulta el tiempo de Madrid y programa una alarma si va a llover"

PASO 1 - AN√ÅLISIS LLM:
LLM Prompt: "Analiza esta petici√≥n y lista las acciones MCP necesarias: 'Consulta el tiempo de Madrid y programa una alarma si va a llover'"

LLM Response: {
  "subtasks": [
    {
      "action": "consultar_tiempo",
      "entities": {"ubicacion": "Madrid"},
      "description": "Consultar informaci√≥n meteorol√≥gica de Madrid"
    },
    {
      "action": "programar_alarma_condicional", 
      "entities": {"condicion": "si_llueve", "ubicacion": "Madrid"},
      "description": "Programar alarma basada en condici√≥n meteorol√≥gica",
      "depends_on_result": "consultar_tiempo"
    }
  ]
}

PASO 2 - EJECUCI√ìN ORQUESTADA:
- Estado inicial: PENDING [consultar_tiempo, programar_alarma_condicional]
- Ejecuta: consultar_tiempo(Madrid) ‚Üí Resultado: "Lluvia probable 70%"  
- Estado: PENDING [programar_alarma_condicional], COMPLETED [consultar_tiempo]
- Ejecuta: programar_alarma_condicional(condicion="si_llueve") ‚Üí Resultado: "Alarma creada"
- Estado: COMPLETED [consultar_tiempo, programar_alarma_condicional]
- CONVERSACI√ìN COMPLETADA: "En Madrid hay 70% probabilidad de lluvia. He programado una alarma para avisarte."
```

### Configuraci√≥n de MCPs Disponibles (mcp_registry.json)
```json
{
  "available_mcps": {
    "consultar_tiempo": {
      "description": "Consulta informaci√≥n meteorol√≥gica de una ubicaci√≥n",
      "required_entities": ["ubicacion"],
      "service_endpoint": "weather-mcp-service"
    },
    "programar_alarma": {
      "description": "Programa una alarma para una fecha/hora espec√≠fica", 
      "required_entities": ["fecha_hora", "mensaje"],
      "service_endpoint": "system-mcp-service"
    },
    "programar_alarma_condicional": {
      "description": "Programa alarma basada en condiciones externas",
      "required_entities": ["condicion"],
      "service_endpoint": "system-mcp-service"
    },
    "crear_github_issue": {
      "description": "Crea un issue en un repositorio de GitHub",
      "required_entities": ["titulo", "descripcion"],
      "service_endpoint": "github-mcp-service"
    }
  }
}
```

### **üéØ OBJETIVO COMPLETO (Futuras Tareas)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Audio     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JSON    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WHISPER-MS     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  GATEWAY-MS     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ INTENTMGR-V2    ‚îÇ
‚îÇ  (Transcripci√≥n)‚îÇ              ‚îÇ  (Routing)      ‚îÇ            ‚îÇ (LLM-RAG+MoE)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                          ‚îÇ
                                                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VECTOR STORE    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   RAG ENGINE    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  EXPERT ROUTER  ‚îÇ
‚îÇ (Embeddings)    ‚îÇ              ‚îÇ (Similarity)    ‚îÇ            ‚îÇ  (MoE Selection) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                          ‚îÇ
                                                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     LLM-A       ‚îÇ              ‚îÇ     LLM-B       ‚îÇ    ‚îÇ     LLM-C       ‚îÇ
‚îÇ   (GPT-4)       ‚îÇ              ‚îÇ  (Claude-3)     ‚îÇ    ‚îÇ (GPT-3.5-Turbo) ‚îÇ
‚îÇ   "Voto: X"     ‚îÇ              ‚îÇ   "Voto: Y"     ‚îÇ    ‚îÇ   "Voto: Z"     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                ‚îÇ                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ CONSENSUS ENGINE‚îÇ
                ‚îÇ (Procesa votos) ‚îÇ
                ‚îÇ Decisi√≥n final  ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CONVERSATION    ‚îÇ              ‚îÇ   MCP ACTIONS   ‚îÇ    ‚îÇ   SINGLE LLM    ‚îÇ
‚îÇ   MANAGER       ‚îÇ              ‚îÇ (Taiga/Weather) ‚îÇ    ‚îÇ   (Fallback)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```