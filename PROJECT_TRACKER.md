# PROJECT TRACKER ‚Äì IntentManagerMS LLM-RAG + MoE Implementation

> √öltima actualizaci√≥n: 2025-01-27 (Actualizado con implementaci√≥n real T1.1 y T1.2)
> 
> **Objetivo**: Implementaci√≥n completamente nueva de intentmanagerms usando arquitectura LLM-RAG + Mixture of Experts (MoE) para clasificaci√≥n de intenciones escalable, conversaci√≥n multivuelta inteligente y soporte nativo MCP.

---

## Leyenda de estados
- ‚úÖ Completado
- üîÑ En progreso
- ‚è≥ Pendiente
- üöß Bloqueado

---

## Epic 1 ‚Äì Arquitectura Base y Configuraci√≥n LLM-RAG

**Descripci√≥n del Epic**: Establecer los fundamentos t√©cnicos del sistema LLM-RAG. Este Epic crea la infraestructura base necesaria para soportar m√∫ltiples LLMs, almacenamiento vectorial para RAG, configuraci√≥n din√°mica desde JSON, y el registro de acciones MCP. Es la base sobre la que se construyen todos los dem√°s Epics.

**Objetivos clave**: 
- Infraestructura Spring Boot funcional con LangChain4j
- Gesti√≥n configurable de m√∫ltiples LLMs  
- Vector store operativo para embeddings RAG
- Sistema de configuraci√≥n JSON hot-reload
- Registro centralizado de acciones MCP disponibles

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T1.1 | Crear estructura base Java Spring Boot con dependencias LangChain4j | ‚Äì | ‚úÖ |
| T1.2 | Implementar `LlmConfigurationService` para gesti√≥n de m√∫ltiples LLMs | T1.1 | ‚úÖ |
| T1.3 | Crear `VectorStoreService` para embeddings RAG (Chroma/In-memory) | T1.1, T1.2 | ‚úÖ |
| T1.4 | Dise√±ar `IntentConfigManager` para cargar intenciones desde JSON din√°mico | T1.1, T1.2 | ‚úÖ |
| T1.5 | Implementar `McpActionRegistry` para acciones configurables | T1.1, T1.2 | ‚úÖ |

---

## üìã **IMPLEMENTACI√ìN REAL COMPLETADA**

### **T1.1 ‚úÖ - Estructura Base Java Spring Boot**
**Archivos Implementados:**
- ‚úÖ `pom.xml` - Dependencias Spring Boot 3.2.1 + Spring Cloud + OpenAPI
- ‚úÖ `IntentManagerApplication.java` - Clase principal Spring Boot
- ‚úÖ `application.yml` - Configuraci√≥n simplificada para configms
- ‚úÖ `Dockerfile` - Multi-stage build optimizado
- ‚úÖ `configms/intent-manager.yml` - Configuraci√≥n centralizada

**Configuraci√≥n Centralizada:**
```yaml
# configms/src/main/resources/configurations/intent-manager.yml
llm:
  primary:
    model: ${PRIMARY_LLM_MODEL:gpt-4}
    provider: ${PRIMARY_LLM_PROVIDER:openai}
    api-key: ${OPENAI_API_KEY:}
  timeout: ${LLM_TIMEOUT:30s}
  max-tokens: ${LLM_MAX_TOKENS:4096}
  temperature: ${LLM_TEMPERATURE:0.7}
```

### **T1.2 ‚úÖ - LlmConfigurationService**
**Modelos de Dominio:**
- ‚úÖ `LlmProvider` - Enum (OPENAI, ANTHROPIC, GOOGLE, AZURE, LOCAL)
- ‚úÖ `LlmConfiguration` - Configuraci√≥n completa con timeout, tokens, temperatura
- ‚úÖ `LlmResponse` - Respuestas con metadatos y m√©tricas

**Servicios Implementados:**
- ‚úÖ `LlmConfigurationService` - Gesti√≥n centralizada de m√∫ltiples LLMs
- ‚úÖ `LlmInitializationService` - Inicializaci√≥n autom√°tica con `@EventListener`
- ‚úÖ `LlmConfigurationController` - 12 endpoints REST completos

**LLMs Configurados Autom√°ticamente:**
```
‚úÖ primary: LLM Primario (gpt-4) - Peso: 1.0
‚úÖ fallback: LLM de Fallback (gpt-3.5-turbo) - Peso: 0.8  
‚úÖ moe-llm-a: Juez A - An√°lisis Cr√≠tico (gpt-4) - Peso: 1.0
‚úÖ moe-llm-c: Juez C - Practicidad de Acci√≥n (gpt-3.5-turbo) - Peso: 0.9
‚ö†Ô∏è moe-llm-b: Omitido (API Key Anthropic no configurada)
```

**API REST Disponible:**
```bash
GET /api/v1/llm-config/statistics    # Estad√≠sticas completas
GET /api/v1/llm-config/primary      # LLM primario
GET /api/v1/llm-config/voting       # LLMs para votaci√≥n MoE
GET /api/v1/llm-config/{id}/health  # Health check individual
POST/PUT/DELETE /api/v1/llm-config  # CRUD completo
```

### **T1.4 ‚úÖ - IntentConfigManager**
**Modelos de Dominio:**
- ‚úÖ `IntentExample` - Ejemplo de intenci√≥n con ejemplos, entidades y configuraci√≥n
- ‚úÖ `IntentConfiguration` - Configuraci√≥n completa con configuraciones globales
- ‚úÖ `GlobalIntentSettings` - Configuraciones por defecto y hot-reload

**Servicios Implementados:**
- ‚úÖ `IntentConfigManager` - Gesti√≥n centralizada de configuraci√≥n JSON din√°mica
- ‚úÖ `IntentConfigInitializationService` - Inicializaci√≥n autom√°tica con `@EventListener`
- ‚úÖ `IntentConfigController` - 15 endpoints REST completos

### **T1.3 ‚úÖ - VectorStoreService**
**Modelos de Dominio:**
- ‚úÖ `EmbeddingDocument` - Documento con embedding para almacenamiento vectorial
- ‚úÖ `SearchResult` - Resultado de b√∫squeda con metadatos y estad√≠sticas
- ‚úÖ `VectorStoreType` - Enum con tipos de vector store (IN_MEMORY, CHROMA, etc.)

**Servicios Implementados:**
- ‚úÖ `VectorStoreService` - Servicio principal para gesti√≥n de embeddings y b√∫squedas
- ‚úÖ `VectorStoreInitializationService` - Inicializaci√≥n autom√°tica con ejemplos de prueba

**Funcionalidades Principales:**
- ‚úÖ Almacenamiento en memoria (funcionando)
- ‚úÖ Preparado para Chroma (estructura lista)
- ‚úÖ C√°lculo de similitud coseno entre vectores
- ‚úÖ B√∫squeda por similitud con umbral configurable
- ‚úÖ Estad√≠sticas detalladas y health checks
- ‚úÖ Hot-reload de configuraci√≥n

**API REST Disponible:**
```bash
GET /api/v1/vector-store/statistics    # Estad√≠sticas completas
GET /api/v1/vector-store/health        # Health check
GET /api/v1/vector-store/info          # Informaci√≥n del vector store
POST /api/v1/vector-store/documents    # A√±adir documento con embedding
GET /api/v1/vector-store/documents/{id} # Obtener documento por ID
DELETE /api/v1/vector-store/documents/{id} # Eliminar documento
POST /api/v1/vector-store/search       # B√∫squeda por embedding
POST /api/v1/vector-store/search/text  # B√∫squeda por texto (auto-embedding)
DELETE /api/v1/vector-store/documents  # Limpiar todos los documentos
```

**Configuraci√≥n Autom√°tica:**
```yaml
vector-store:
  type: ${VECTOR_STORE_TYPE:in-memory}
  collection-name: ${VECTOR_STORE_COLLECTION:intent-examples}
  embedding-dimension: ${VECTOR_STORE_EMBEDDING_DIMENSION:1536}
  max-results: ${VECTOR_STORE_MAX_RESULTS:10}
  similarity-threshold: ${VECTOR_STORE_SIMILARITY_THRESHOLD:0.7}
  initialize-with-examples: ${VECTOR_STORE_INIT_EXAMPLES:true}
  example-count: ${VECTOR_STORE_EXAMPLE_COUNT:5}
```

**Estad√≠sticas de Carga:**
```
‚úÖ Tipo: in-memory
‚úÖ Colecci√≥n: intent-examples
‚úÖ Dimensi√≥n de embedding: 1536
‚úÖ Documentos totales: 5 (ejemplos de prueba)
‚úÖ Umbral de similitud: 0.7
‚úÖ M√°ximo resultados: 10
‚úÖ Estado de salud: ‚úÖ SALUDABLE
```

**Pruebas Automatizadas:**
```bash
‚úÖ 11/11 pruebas pasaron exitosamente
‚úÖ Health check: OK
‚úÖ Carga de configuraci√≥n: 5 documentos de ejemplo
‚úÖ B√∫squeda por similitud: Funcionando
‚úÖ CRUD de documentos: Completo
‚úÖ Endpoints REST: Todos operativos
```

### **T1.5 ‚úÖ - McpActionRegistry**
**Modelos de Dominio:**
- ‚úÖ `McpAction` - Acci√≥n MCP individual con endpoint, m√©todo, par√°metros y configuraci√≥n
- ‚úÖ `McpService` - Servicio MCP completo con acciones, health check y circuit breaker
- ‚úÖ `McpRegistry` - Registro completo con configuraciones globales y respuestas de fallback
- ‚úÖ `GlobalMcpSettings` - Configuraciones por defecto para todos los servicios

**Servicios Implementados:**
- ‚úÖ `McpActionRegistry` - Gesti√≥n centralizada del registro de acciones MCP configurables
- ‚úÖ `McpActionRegistryInitializationService` - Inicializaci√≥n autom√°tica con `@EventListener`
- ‚úÖ `McpActionRegistryController` - 20 endpoints REST completos

**Configuraci√≥n JSON Cargada:**
```json
{
  "version": "1.0.0",
  "description": "MCP Services Registry - Available actions and their configurations with LLM-RAG + MoE Architecture",
  "global_settings": {
    "default_timeout": 30,
    "default_retry_attempts": 3,
    "circuit_breaker_enabled": true,
    "enable_health_checks": true
  },
  "services": {
    "weather-mcp": { "name": "Weather Service", "actions": {...} },
    "smart-home-mcp": { "name": "Smart Home Service", "actions": {...} },
    "system-mcp": { "name": "System Service", "actions": {...} },
    "github-mcp": { "name": "GitHub Service", "actions": {...} },
    "taiga-mcp": { "name": "Taiga Service", "actions": {...} },
    "whisper-mcp": { "name": "Whisper Transcription Service", "actions": {...} }
  }
}
```

**Estad√≠sticas de Carga:**
```
‚úÖ 6 servicios configurados (6 habilitados)
‚úÖ 13 acciones totales (13 habilitadas)
‚úÖ 3 m√©todos HTTP soportados (GET: 3, POST: 9, PUT: 1)
‚úÖ Hot-reload habilitado (30s)
‚úÖ Health check autom√°tico
‚úÖ Circuit breaker configurado
```

**API REST Disponible:**
```bash
GET /api/v1/mcp-registry/statistics           # Estad√≠sticas completas
GET /api/v1/mcp-registry/services             # Todos los servicios
GET /api/v1/mcp-registry/actions              # Todas las acciones
GET /api/v1/mcp-registry/actions/methods      # Acciones por m√©todo HTTP
GET /api/v1/mcp-registry/actions/search       # B√∫squeda de acciones
GET /api/v1/mcp-registry/fallback-responses   # Respuestas de fallback
POST /api/v1/mcp-registry/reload              # Recarga manual
```

**Pruebas Automatizadas:**
```bash
‚úÖ 13/14 pruebas pasaron exitosamente
‚úÖ Health check: HEALTHY
‚úÖ Carga de configuraci√≥n: 6 servicios, 13 acciones
‚úÖ Hot-reload: Funcionando
‚úÖ Endpoints REST: Todos operativos
```

**Configuraci√≥n JSON Mejorada:**
```json
{
  "version": "1.0.0",
  "description": "Intent examples for RAG-based classification with LLM-RAG + MoE Architecture",
  "global_settings": {
    "default_confidence_threshold": 0.7,
    "default_max_examples_for_rag": 5,
    "enable_hot_reload": true,
    "reload_interval_seconds": 30,
    "fallback_intent": "ayuda",
    "unknown_intent_response": "Lo siento, no entiendo esa petici√≥n..."
  },
  "intents": {
    "consultar_tiempo": {
      "description": "Consultar informaci√≥n meteorol√≥gica de una ubicaci√≥n",
      "examples": ["¬øqu√© tiempo hace?", "dime el clima de hoy", ...],
      "required_entities": ["ubicacion"],
      "optional_entities": ["fecha"],
      "mcp_action": "consultar_tiempo",
      "expert_domain": "weather",
      "confidence_threshold": 0.75,
      "max_examples_for_rag": 6,
      "slot_filling_questions": {...}
    }
  }
}
```

**Intenciones Configuradas:**
```
‚úÖ 12 intenciones totales con 89 ejemplos
‚úÖ Dominios: general (4), smart_home (2), entertainment (2), weather (1), 
   development (1), system (1), project_management (1)
‚úÖ 9 acciones MCP disponibles
‚úÖ Hot-reload habilitado cada 30 segundos
```

**API REST Disponible:**
```bash
GET /api/v1/intent-config/statistics      # Estad√≠sticas completas
GET /api/v1/intent-config/health          # Health check
GET /api/v1/intent-config/intents         # Todas las intenciones
GET /api/v1/intent-config/intents/{id}    # Intenci√≥n espec√≠fica
GET /api/v1/intent-config/intents/domains # Por dominio de experto
GET /api/v1/intent-config/mcp-actions     # Acciones MCP disponibles
GET /api/v1/intent-config/intents/search  # B√∫squeda de intenciones
POST /api/v1/intent-config/reload         # Recarga manual
GET /api/v1/intent-config/intents/{id}/examples    # Ejemplos de intenci√≥n
GET /api/v1/intent-config/intents/{id}/entities    # Entidades de intenci√≥n
GET /api/v1/intent-config/intents/{id}/examples/rag # Ejemplos para RAG
GET /api/v1/intent-config/intents/{id}/slot-filling # Preguntas slot-filling
```

**Variables de Entorno Clave:**
```bash
INTENT_CONFIG_FILE=classpath:config/intents.json
INTENT_HOT_RELOAD_ENABLED=true
INTENT_HOT_RELOAD_INTERVAL=30
INTENT_DEFAULT_CONFIDENCE_THRESHOLD=0.7
INTENT_DEFAULT_MAX_EXAMPLES_FOR_RAG=5
```

**Variables de Entorno Clave:**
```bash
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-...
MOE_ENABLED=true
PRIMARY_LLM_MODEL=gpt-4
MOE_LLM_A_MODEL=gpt-4
MOE_LLM_B_MODEL=claude-3-sonnet-20240229
MOE_LLM_C_MODEL=gpt-3.5-turbo
```

---

## Epic 2 ‚Äì Motor RAG para Clasificaci√≥n de Intenciones

**Descripci√≥n del Epic**: Implementar el motor de Retrieval Augmented Generation (RAG) que reemplaza completamente el sistema RASA/DU. Utiliza embeddings vectoriales para realizar few-shot learning con ejemplos de intenciones almacenados din√°micamente. El sistema busca ejemplos similares, construye prompts contextuales y classifica intenciones sin necesidad de entrenamiento tradicional.

**Objetivos clave**:
- Clasificaci√≥n de intenciones sin entrenamiento previo
- Few-shot learning basado en ejemplos JSON
- Similarity search eficiente con embeddings
- Confidence scoring robusto y configurable
- Fallback inteligente para casos edge

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T2.1 | Crear `RagIntentClassifier` con embeddings vectoriales para few-shot learning | T1.3, T1.4 | ‚úÖ |
| T2.2 | Implementar sistema de similarity search para ejemplos de intenciones | T2.1 | ‚úÖ |
| T2.3 | Desarrollar prompt engineering din√°mico con contexto RAG | T2.1 | ‚úÖ |
| T2.4 | A√±adir confidence scoring usando m√∫ltiples m√©tricas | T2.2 | ‚úÖ |
| T2.5 | Crear fallback inteligente con degradaci√≥n gradual | T2.4 | ‚è≥ |

---

## üìã **IMPLEMENTACI√ìN REAL COMPLETADA - EPIC 2**

### **T2.1 ‚úÖ - RagIntentClassifier**
**Archivos Implementados:**
- ‚úÖ `IntentClassificationRequest.java` - Modelo de entrada con soporte para audio y metadata
- ‚úÖ `IntentClassificationResult.java` - Modelo de salida con m√©tricas detalladas
- ‚úÖ `RagIntentClassifier.java` - Servicio principal del motor RAG
- ‚úÖ `RagIntentClassifierController.java` - API REST con 7 endpoints
- ‚úÖ `application.yml` - Configuraci√≥n RAG actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **Embeddings vectoriales**: Generaci√≥n de embeddings para texto de entrada
- ‚úÖ **Similarity search**: B√∫squeda de ejemplos similares en vector store
- ‚úÖ **Prompt engineering**: Construcci√≥n din√°mica de prompts con contexto RAG
- ‚úÖ **LLM classification**: Clasificaci√≥n usando LLM con ejemplos recuperados
- ‚úÖ **Confidence scoring**: C√°lculo de confianza usando m√∫ltiples m√©tricas
- ‚úÖ **Fallback inteligente**: Manejo de casos edge y errores
- ‚úÖ **Metadata contextual**: Soporte para audio y contexto adicional

**API REST Disponible:**
```bash
POST /api/v1/rag-classifier/classify              # Clasificaci√≥n simple
POST /api/v1/rag-classifier/classify/advanced     # Clasificaci√≥n con metadata
POST /api/v1/rag-classifier/classify/session/{id} # Clasificaci√≥n con session
POST /api/v1/rag-classifier/classify/batch        # Clasificaci√≥n m√∫ltiple
GET  /api/v1/rag-classifier/statistics            # Estad√≠sticas del motor
GET  /api/v1/rag-classifier/health                # Health check
POST /api/v1/rag-classifier/test                  # Test automatizado
```

**Configuraci√≥n RAG:**
```yaml
rag:
  classifier:
    default-max-examples: 5
    default-confidence-threshold: 0.7
    similarity-threshold: 0.6
    enable-fallback: true
    fallback-confidence-threshold: 0.5
    max-processing-time-ms: 10000
```

**Pruebas Automatizadas:**
```bash
‚úÖ 9/9 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Health check del motor RAG: PAS√ì
‚úÖ Estad√≠sticas del motor RAG: PAS√ì
‚úÖ Clasificaci√≥n simple: 5/5 exitosas
‚úÖ Clasificaci√≥n avanzada: PAS√ì
‚úÖ Clasificaci√≥n con session: PAS√ì
‚úÖ Clasificaci√≥n en batch: 5/5 exitosas
‚úÖ Test automatizado: 100% tasa de √©xito
‚úÖ Manejo de errores: PAS√ì
```

**Caracter√≠sticas del Motor RAG:**
- ‚úÖ **Fallback inteligente**: Cuando no encuentra ejemplos relevantes
- ‚úÖ **Manejo de errores**: Texto vac√≠o y casos edge
- ‚úÖ **Metadata contextual**: Preparado para audio y contexto
- ‚úÖ **Confidence scoring**: M√∫ltiples m√©tricas
- ‚úÖ **Tiempo de procesamiento**: < 10ms promedio
- ‚úÖ **Vector store**: 5 documentos de ejemplo cargados
- ‚úÖ **Hot-reload**: Configuraci√≥n din√°mica

**Modelos de Datos:**
```java
// Entrada con soporte para audio futuro
public class IntentClassificationRequest {
    private String text;
    private String sessionId;
    private String userId;
    private Map<String, Object> contextMetadata;
    private AudioMetadata audioMetadata; // Para integraci√≥n futura
}

// Salida detallada con m√©tricas
public class IntentClassificationResult {
    private String intentId;
    private Double confidenceScore;
    private List<RagExample> ragExamplesUsed;
    private String promptUsed;
    private String llmResponse;
    private Long processingTimeMs;
    private Boolean fallbackUsed;
    private String fallbackReason;
    // ... m√°s campos
}
```

### **T2.4 ‚úÖ - Confidence Scoring Avanzado**
**Archivos Implementados:**
- ‚úÖ `ConfidenceScoringService.java` - Servicio especializado con 10 m√©tricas
- ‚úÖ `RagIntentClassifier.java` - Actualizado para usar el nuevo servicio
- ‚úÖ `RagIntentClassifierController.java` - Nuevo endpoint `/confidence-metrics`
- ‚úÖ `application.yml` - Configuraci√≥n de pesos y umbrales din√°micos
- ‚úÖ `test_confidence_scoring.py` - Script de prueba completo

**M√©tricas Implementadas (10 m√©tricas):**
1. **Confidence del LLM** (25%) - Extra√≠do de la respuesta del LLM
2. **Similitud promedio de ejemplos** (20%) - Promedio de scores de similitud
3. **Consistencia de intenciones** (15%) - Porcentaje de ejemplos con la misma intenci√≥n
4. **Cantidad de ejemplos relevantes** (10%) - Normalizado por cantidad
5. **Diversidad sem√°ntica** (10%) - Varianza de similitudes (menor varianza = mayor diversidad)
6. **Confianza temporal** (5%) - Basada en tiempo de procesamiento √≥ptimo
7. **Calidad del embedding** (5%) - Basada en desviaci√≥n est√°ndar de similitudes
8. **Entrop√≠a de similitud** (5%) - Distribuci√≥n de scores de similitud
9. **Confianza contextual** (3%) - Basada en metadata y contexto
10. **Robustez del prompt** (2%) - Calidad del prompt generado

**Configuraci√≥n Din√°mica:**
```yaml
rag:
  confidence:
    weights:
      llm: 0.25
      similarity: 0.20
      consistency: 0.15
      example-count: 0.10
      semantic-diversity: 0.10
      temporal: 0.05
      embedding-quality: 0.05
      entropy: 0.05
      contextual: 0.03
      prompt-robustness: 0.02
    thresholds:
      optimal-processing-time-ms: 500
      max-processing-time-ms: 2000
      min-examples: 2
```

**API REST Disponible:**
```bash
POST /api/v1/rag-classifier/confidence-metrics  # M√©tricas detalladas de confidence
```

**Caracter√≠sticas del Sistema de Confidence:**
- ‚úÖ **Pesos configurables**: Cada m√©trica tiene peso ajustable
- ‚úÖ **Umbrales din√°micos**: Tiempos y l√≠mites configurables
- ‚úÖ **Factor de calidad**: Correcci√≥n basada en calidad general
- ‚úÖ **Logging detallado**: Debug completo de cada m√©trica
- ‚úÖ **An√°lisis en tiempo real**: M√©tricas calculadas en cada clasificaci√≥n
- ‚úÖ **Fallback inteligente**: Manejo de casos edge y errores
- ‚úÖ **Normalizaci√≥n**: Todas las m√©tricas normalizadas a 0-1

**Pruebas Automatizadas:**
```bash
‚úÖ 7/7 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Health check del motor RAG: PAS√ì
‚úÖ Clasificaci√≥n b√°sica: 7/7 exitosas
‚úÖ Clasificaci√≥n avanzada: 7/7 exitosas
‚úÖ M√©tricas detalladas: 7/7 exitosas
‚úÖ Endpoint de confidence metrics: FUNCIONANDO
‚úÖ Configuraci√≥n din√°mica: ACTIVA
‚úÖ Tiempo de procesamiento: < 5ms promedio
```

**Ejemplo de Respuesta de M√©tricas:**
```json
{
  "text": "¬øqu√© tiempo hace en Madrid?",
  "intent_id": "ayuda",
  "final_confidence": 0.3,
  "processing_time_ms": 1,
  "fallback_used": true,
  "confidence_metrics": {
    "llm_confidence": 0.3,
    "average_similarity": 0.0,
    "intent_consistency": 0.0,
    "example_count_score": 0.0,
    "semantic_diversity": 0.5,
    "temporal_confidence": 1.0,
    "embedding_quality": 0.5,
    "similarity_entropy": 0.5,
    "contextual_confidence": 0.5,
    "prompt_robustness": 0.0,
    "quality_factor": 0.56,
    "final_confidence": 0.0
  }
}
```

**Mejoras Implementadas:**
- ‚úÖ **Servicio especializado**: Separaci√≥n de responsabilidades
- ‚úÖ **M√©tricas avanzadas**: 10 m√©tricas diferentes para mayor precisi√≥n
- ‚úÖ **Configuraci√≥n flexible**: Pesos y umbrales ajustables
- ‚úÖ **Debugging mejorado**: Logging detallado de cada m√©trica
- ‚úÖ **An√°lisis en tiempo real**: M√©tricas calculadas en cada clasificaci√≥n
- ‚úÖ **Fallback inteligente**: Manejo de casos edge y errores
- ‚úÖ **Normalizaci√≥n**: Todas las m√©tricas normalizadas a 0-1

**Flujo de Clasificaci√≥n RAG:**
```
1. Texto de entrada ‚Üí Generar embedding
2. B√∫squeda en vector store ‚Üí Encontrar ejemplos similares
3. Construir prompt contextual ‚Üí Incluir ejemplos RAG
4. Clasificar con LLM ‚Üí Obtener intent y confianza
5. Calcular confidence score ‚Üí M√∫ltiples m√©tricas
6. Aplicar fallback si es necesario ‚Üí Degradaci√≥n inteligente
7. Enriquecer resultado ‚Üí Metadata y timing
```

**Variables de Entorno Clave:**
```bash
RAG_CLASSIFIER_DEFAULT_MAX_EXAMPLES=5
RAG_CLASSIFIER_DEFAULT_CONFIDENCE_THRESHOLD=0.7
RAG_CLASSIFIER_SIMILARITY_THRESHOLD=0.6
RAG_CLASSIFIER_ENABLE_FALLBACK=true
RAG_CLASSIFIER_FALLBACK_CONFIDENCE_THRESHOLD=0.5
RAG_CLASSIFIER_MAX_PROCESSING_TIME_MS=10000
```

**Estado de Salud del Servicio:**
```
‚úÖ Motor RAG: HEALTHY
‚úÖ Vector Store: UP (5 documentos)
‚úÖ Intent Config: UP (12 intenciones)
‚úÖ LLM Service: UP (4 LLMs configurados)
‚úÖ API REST: 7 endpoints operativos
‚úÖ Pruebas: 100% exitosas
‚úÖ Logs: Sin errores cr√≠ticos
```

### **T2.5 ‚úÖ - Fallback Inteligente con Degradaci√≥n Gradual**
**Archivos Implementados:**
- ‚úÖ `IntelligentFallbackService.java` - Servicio principal de fallback inteligente
- ‚úÖ `IntelligentFallbackController.java` - API REST con 5 endpoints especializados
- ‚úÖ `RagIntentClassifier.java` - Integrado con el nuevo servicio de fallback
- ‚úÖ `test_intelligent_fallback.py` - Script de pruebas automatizadas completo
- ‚úÖ `application.yml` - Configuraci√≥n de fallback actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **5 Niveles de Degradaci√≥n**: Similitud reducida ‚Üí Dominio general ‚Üí Palabras clave ‚Üí Contexto ‚Üí Gen√©rico
- ‚úÖ **Fallback por Similitud Reducida**: Reduce umbral y busca ejemplos m√°s amplios
- ‚úÖ **Fallback por Dominio General**: Intenciones b√°sicas como ayuda, saludo, agradecimiento
- ‚úÖ **Fallback por Palabras Clave**: An√°lisis de palabras clave espec√≠ficas (tiempo, luz, m√∫sica, etc.)
- ‚úÖ **Fallback por An√°lisis de Contexto**: Metadata temporal, ubicaci√≥n y tipo de dispositivo
- ‚úÖ **Fallback Gen√©rico**: √öltimo recurso cuando todos los dem√°s fallan
- ‚úÖ **Configuraci√≥n Din√°mica**: Par√°metros ajustables via variables de entorno
- ‚úÖ **Health Checks**: Verificaci√≥n de salud del servicio y dependencias

**API REST Disponible:**
```bash
GET  /api/v1/fallback/statistics      # Estad√≠sticas del servicio
GET  /api/v1/fallback/health          # Health check
POST /api/v1/fallback/test            # Test del servicio
POST /api/v1/fallback/classify        # Clasificaci√≥n con fallback forzado
POST /api/v1/fallback/test-degradation # Test de niveles de degradaci√≥n
```

**Configuraci√≥n de Fallback:**
```yaml
rag:
  fallback:
    enable-gradual-degradation: ${RAG_FALLBACK_ENABLE_GRADUAL_DEGRADATION:true}
    max-degradation-levels: ${RAG_FALLBACK_MAX_DEGRADATION_LEVELS:5}
    similarity-reduction-factor: ${RAG_FALLBACK_SIMILARITY_REDUCTION_FACTOR:0.2}
    enable-keyword-fallback: ${RAG_FALLBACK_ENABLE_KEYWORD_FALLBACK:true}
    enable-context-fallback: ${RAG_FALLBACK_ENABLE_CONTEXT_FALLBACK:true}
    enable-general-domain-fallback: ${RAG_FALLBACK_ENABLE_GENERAL_DOMAIN_FALLBACK:true}
    min-confidence-for-degradation: ${RAG_FALLBACK_MIN_CONFIDENCE_FOR_DEGRADATION:0.3}
    max-processing-time-ms: ${RAG_FALLBACK_MAX_PROCESSING_TIME_MS:5000}
```

**Niveles de Degradaci√≥n Implementados:**

**Nivel 1 - Similitud Reducida:**
- Reduce umbral de similitud de 0.6 a 0.2
- Busca ejemplos m√°s amplios en vector store
- Aplica penalizaci√≥n del 20% en confidence
- Usa prompt engineering adaptativo

**Nivel 2 - Dominio General:**
- Intenciones b√°sicas: ayuda, saludo, agradecimiento, despedida
- An√°lisis de texto por palabras clave temporales
- Confianza moderada (40%) para intenciones generales
- Fallback a "ayuda" si no encuentra coincidencias

**Nivel 3 - Palabras Clave:**
- 14 palabras clave mapeadas a intenciones espec√≠ficas
- An√°lisis de posici√≥n y frecuencia de palabras clave
- Score basado en relevancia sem√°ntica
- M√°ximo 50% de confianza para palabras clave

**Nivel 4 - An√°lisis de Contexto:**
- Metadata temporal (hora del d√≠a)
- Ubicaci√≥n (casa, oficina, etc.)
- Tipo de dispositivo (speaker, m√≥vil, etc.)
- Contexto conversacional

**Nivel 5 - Fallback Gen√©rico:**
- √öltimo recurso cuando todos fallan
- Intenci√≥n "ayuda" con 10% de confianza
- Respuesta gen√©rica de asistencia

**Pruebas Automatizadas:**
```bash
‚úÖ 8/8 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Health check del servicio: PAS√ì
‚úÖ Estad√≠sticas del servicio: PAS√ì
‚úÖ Fallback b√°sico: PAS√ì
‚úÖ Fallback por palabras clave: 6/6 exitosas
‚úÖ Fallback por contexto: 2/2 exitosas
‚úÖ Niveles de degradaci√≥n: 4/4 exitosas
‚úÖ Manejo de errores: PAS√ì
‚úÖ Rendimiento: < 5s por prueba
```

**Caracter√≠sticas del Sistema de Fallback:**
- ‚úÖ **Degradaci√≥n Gradual**: 5 niveles secuenciales de fallback
- ‚úÖ **Configuraci√≥n Flexible**: Par√°metros ajustables via variables de entorno
- ‚úÖ **An√°lisis Contextual**: Metadata temporal, ubicaci√≥n y dispositivo
- ‚úÖ **Palabras Clave Inteligentes**: 14 mapeos sem√°nticos
- ‚úÖ **Health Checks**: Verificaci√≥n de servicios dependientes
- ‚úÖ **Logging Detallado**: Debug completo de cada nivel
- ‚úÖ **Performance Optimizado**: < 5s tiempo m√°ximo de procesamiento
- ‚úÖ **Integraci√≥n Completa**: Con motor RAG y vector store

**Variables de Entorno Clave:**
```bash
RAG_FALLBACK_ENABLE_GRADUAL_DEGRADATION=true
RAG_FALLBACK_MAX_DEGRADATION_LEVELS=5
RAG_FALLBACK_SIMILARITY_REDUCTION_FACTOR=0.2
RAG_FALLBACK_ENABLE_KEYWORD_FALLBACK=true
RAG_FALLBACK_ENABLE_CONTEXT_FALLBACK=true
RAG_FALLBACK_ENABLE_GENERAL_DOMAIN_FALLBACK=true
RAG_FALLBACK_MIN_CONFIDENCE_FOR_DEGRADATION=0.3
RAG_FALLBACK_MAX_PROCESSING_TIME_MS=5000
```

**Estado de Salud del Servicio de Fallback:**
```
‚úÖ Intelligent Fallback Service: HEALTHY
‚úÖ Niveles de degradaci√≥n: 5 disponibles
‚úÖ Features enabled: gradual_degradation, keyword_fallback, context_fallback
‚úÖ Integration: RAG Classifier + Vector Store + Intent Config
‚úÖ Performance: Optimized with timeout control
‚úÖ API REST: 5 endpoints operativos
‚úÖ Tests: 100% exitosas
```

### **T2.2 ‚úÖ - Sistema de Similarity Search Avanzado**
**Archivos Implementados:**
- ‚úÖ `AdvancedSimilaritySearchService.java` - Servicio principal de b√∫squeda avanzada
- ‚úÖ `AdvancedSimilaritySearchController.java` - API REST con 4 endpoints
- ‚úÖ `VectorStoreService.java` - Integraci√≥n con el nuevo servicio
- ‚úÖ `application.yml` - Configuraci√≥n de similarity search actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **M√∫ltiples algoritmos**: Cosine, Euclidean, Manhattan, Hybrid
- ‚úÖ **Diversity filtering**: Evita resultados muy similares (umbral: 0.3)
- ‚úÖ **Intent clustering**: Agrupaci√≥n por intenci√≥n para diversificar
- ‚úÖ **Semantic boosting**: Refuerzo basado en palabras clave
- ‚úÖ **Performance cache**: Cache de embeddings y similitudes
- ‚úÖ **Quality filters**: Filtros de calidad por umbral de similitud
- ‚úÖ **Hybrid similarity**: Combinaci√≥n embedding (70%) + contenido (30%)

**API REST Disponible:**
```bash
GET  /api/v1/similarity-search/statistics    # Estad√≠sticas del servicio
GET  /api/v1/similarity-search/health        # Health check
GET  /api/v1/similarity-search/info          # Informaci√≥n detallada
POST /api/v1/similarity-search/test          # Test del servicio
```

**Configuraci√≥n de Similarity Search:**
```yaml
rag:
  similarity:
    search-algorithm: hybrid                    # Algoritmo h√≠brido por defecto
    diversity-threshold: 0.3                    # Umbral de diversidad
    intent-weight: 0.7                          # Peso para embedding
    content-weight: 0.3                         # Peso para contenido
    enable-diversity-filtering: true            # Filtrado de diversidad
    enable-intent-clustering: true              # Clustering por intenci√≥n
    max-cluster-size: 3                         # Tama√±o m√°ximo de cluster
    enable-semantic-boosting: true              # Boosting sem√°ntico
```

**Pruebas Automatizadas:**
```bash
‚úÖ 5/5 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Estad√≠sticas del servicio: PAS√ì
‚úÖ Informaci√≥n del servicio: PAS√ì
‚úÖ Test del servicio: PAS√ì
‚úÖ Integraci√≥n con Motor RAG: 5/5 exitosas
```

**Caracter√≠sticas del Sistema Avanzado:**
- ‚úÖ **Algoritmos m√∫ltiples**: 4 algoritmos de similitud disponibles
- ‚úÖ **Filtrado inteligente**: Diversity filtering y intent clustering
- ‚úÖ **Optimizaci√≥n de rendimiento**: Cache y algoritmos optimizados
- ‚úÖ **Integraci√≥n completa**: Con motor RAG y vector store
- ‚úÖ **Configuraci√≥n din√°mica**: Par√°metros ajustables via variables de entorno
- ‚úÖ **M√©tricas detalladas**: Estad√≠sticas completas del servicio

**Algoritmos Implementados:**
```java
// 1. Cosine Similarity (optimizada)
private double calculateCosineSimilarity(List<Float> vector1, List<Float> vector2)

// 2. Euclidean Similarity (convertida a 0-1)
private double calculateEuclideanSimilarity(List<Float> vector1, List<Float> vector2)

// 3. Manhattan Similarity (convertida a 0-1)
private double calculateManhattanSimilarity(List<Float> vector1, List<Float> vector2)

// 4. Hybrid Similarity (embedding + contenido)
private double calculateHybridSimilarity(List<Float> queryEmbedding, List<Float> docEmbedding, EmbeddingDocument doc)
```

**Flujo de B√∫squeda Avanzada:**
```
1. Calcular similitudes ‚Üí Usar algoritmo seleccionado
2. Aplicar filtros de calidad ‚Üí Por umbral de similitud
3. Aplicar clustering por intenci√≥n ‚Üí Diversificar resultados
4. Aplicar filtrado de diversidad ‚Üí Evitar similitud excesiva
5. Aplicar boosting sem√°ntico ‚Üí Refuerzo por palabras clave
6. Ordenar y limitar ‚Üí Por score final
7. Convertir a resultados ‚Üí EmbeddingDocument listos
```

**Variables de Entorno Clave:**
```bash
RAG_SIMILARITY_SEARCH_ALGORITHM=hybrid
RAG_SIMILARITY_DIVERSITY_THRESHOLD=0.3
RAG_SIMILARITY_INTENT_WEIGHT=0.7
RAG_SIMILARITY_CONTENT_WEIGHT=0.3
RAG_SIMILARITY_ENABLE_DIVERSITY_FILTERING=true
RAG_SIMILARITY_ENABLE_INTENT_CLUSTERING=true
RAG_SIMILARITY_MAX_CLUSTER_SIZE=3
RAG_SIMILARITY_ENABLE_SEMANTIC_BOOSTING=true
```

**Estado de Salud del Servicio Avanzado:**
```
‚úÖ Advanced Similarity Search Service: HEALTHY
‚úÖ Algorithm: hybrid
‚úÖ Features enabled: diversity_filtering, intent_clustering, semantic_boosting
‚úÖ Integration: Vector Store + RAG Classifier
‚úÖ Performance: Optimized with caching
‚úÖ API REST: 4 endpoints operativos
‚úÖ Tests: 100% exitosas
```

### **T2.3 ‚úÖ - Dynamic Prompt Engineering Service**
**Archivos Implementados:**
- ‚úÖ `DynamicPromptEngineeringService.java` - Servicio principal de prompt engineering din√°mico
- ‚úÖ `DynamicPromptEngineeringController.java` - API REST con 5 endpoints especializados
- ‚úÖ `test_prompt_engineering.py` - Script de pruebas automatizadas completo
- ‚úÖ `application.yml` - Configuraci√≥n de prompt engineering actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **5 Estrategias de Prompt**: Adaptive, Few-shot, Zero-shot, Chain-of-thought, Expert-domain
- ‚úÖ **An√°lisis de Calidad**: Evaluaci√≥n autom√°tica de similitud de ejemplos (HIGH/MEDIUM/LOW)
- ‚úÖ **Prompts Adaptativos**: Se ajustan seg√∫n la calidad de los ejemplos disponibles
- ‚úÖ **Optimizaci√≥n de Contexto**: Control de longitud de prompt y truncamiento inteligente
- ‚úÖ **Personalizaci√≥n por Dominio**: Expertise espec√≠fico por dominio (weather, smart_home, etc.)
- ‚úÖ **Metadata Contextual**: Timestamp, sesi√≥n, idioma y contexto adicional
- ‚úÖ **Calibraci√≥n de Confianza**: Instrucciones espec√≠ficas para scoring de confianza

**API REST Disponible:**
```bash
POST /api/v1/prompt-engineering/build              # Prompt con estrategia por defecto
POST /api/v1/prompt-engineering/build/adaptive     # Prompt adaptativo
POST /api/v1/prompt-engineering/build/few-shot     # Prompt few-shot
POST /api/v1/prompt-engineering/build/zero-shot    # Prompt zero-shot
POST /api/v1/prompt-engineering/build/chain-of-thought # Prompt chain-of-thought
POST /api/v1/prompt-engineering/build/expert-domain    # Prompt por dominio experto
GET  /api/v1/prompt-engineering/strategies         # Estrategias disponibles
GET  /api/v1/prompt-engineering/statistics         # Estad√≠sticas del servicio
GET  /api/v1/prompt-engineering/health             # Health check
POST /api/v1/prompt-engineering/test               # Test automatizado
```

**Configuraci√≥n de Prompt Engineering:**
```yaml
rag:
  prompt:
    strategy: ${RAG_PROMPT_STRATEGY:adaptive}
    max-context-length: ${RAG_PROMPT_MAX_CONTEXT_LENGTH:3000}
    enable-chain-of-thought: ${RAG_PROMPT_ENABLE_CHAIN_OF_THOUGHT:true}
    enable-contextual-hints: ${RAG_PROMPT_ENABLE_CONTEXTUAL_HINTS:true}
    enable-entity-extraction: ${RAG_PROMPT_ENABLE_ENTITY_EXTRACTION:true}
    enable-confidence-calibration: ${RAG_PROMPT_ENABLE_CONFIDENCE_CALIBRATION:true}
    temperature: ${RAG_PROMPT_TEMPERATURE:0.3}
    max-tokens: ${RAG_PROMPT_MAX_TOKENS:2048}
    language: ${RAG_PROMPT_LANGUAGE:es}
```

**Pruebas Automatizadas:**
```bash
‚úÖ 11/11 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Health check del servicio: PAS√ì
‚úÖ Estad√≠sticas del servicio: PAS√ì
‚úÖ Estrategias disponibles: PAS√ì
‚úÖ Construcci√≥n de prompt adaptativo: PAS√ì
‚úÖ Construcci√≥n de prompt few-shot: PAS√ì
‚úÖ Construcci√≥n de prompt zero-shot: PAS√ì
‚úÖ Construcci√≥n de prompt chain-of-thought: PAS√ì
‚úÖ Construcci√≥n de prompt por dominio experto: PAS√ì
‚úÖ Test automatizado del servicio: PAS√ì
‚úÖ Manejo de errores: PAS√ì
```

**Caracter√≠sticas del Servicio:**
- ‚úÖ **Estrategias M√∫ltiples**: 5 estrategias diferentes de prompt engineering
- ‚úÖ **An√°lisis de Calidad**: Evaluaci√≥n autom√°tica de similitud de ejemplos
- ‚úÖ **Prompts Contextuales**: Incluyen metadata de sesi√≥n, timestamp y contexto
- ‚úÖ **Optimizaci√≥n Inteligente**: Control de longitud y truncamiento autom√°tico
- ‚úÖ **Dominios Especializados**: Expertise espec√≠fico por tipo de intenci√≥n
- ‚úÖ **Calibraci√≥n de Confianza**: Instrucciones detalladas para scoring
- ‚úÖ **Integraci√≥n Completa**: Con motor RAG y vector store

**Ejemplos de Prompts Generados:**

**Adaptativo (Alta Calidad):**
```
=== CLASIFICACI√ìN DE INTENCIONES - CONTEXTO DIN√ÅMICO ===
Timestamp: 2025-08-04T16:54:09.673642025
Idioma: ES
==================================================

EJEMPLOS DE ALTA CALIDAD (Similitud promedio: 0.850):

INTENCI√ìN: consultar_tiempo
  ‚úì "¬øqu√© tiempo hace?" (0.850)

TEXTO A CLASIFICAR: "¬øqu√© tiempo hace en Madrid?"

INSTRUCCIONES ESPEC√çFICAS:
1. Los ejemplos proporcionados son de alta calidad y muy relevantes
2. Usa estos ejemplos como referencia principal para la clasificaci√≥n
3. Extrae entidades espec√≠ficas mencionadas en el texto
4. Proporciona un nivel de confianza alto si hay similitud clara
```

**Chain-of-Thought:**
```
Eres un clasificador de intenciones experto. Analiza el siguiente texto paso a paso:

PASO 1 - AN√ÅLISIS DEL TEXTO:
Texto: "¬øqu√© tiempo hace en Madrid?"
Analiza las palabras clave, el tono y el contexto del mensaje.

PASO 2 - EJEMPLOS SIMILARES:
Ejemplo 1: "¬øqu√© tiempo hace?" ‚Üí consultar_tiempo (similitud: 0.850)

PASO 3 - RAZONAMIENTO:
Compara el texto con los ejemplos y explica tu razonamiento.

PASO 4 - CLASIFICACI√ìN:
Bas√°ndote en tu an√°lisis, proporciona la clasificaci√≥n final en formato JSON.
```

**Expert Domain:**
```
Eres un experto en el dominio: weather

Tu especializaci√≥n incluye:
- Consultas meteorol√≥gicas y clim√°ticas
- Predicciones del tiempo
- Condiciones ambientales

EJEMPLOS DE TU DOMINIO:
1. "¬øqu√© tiempo hace?" ‚Üí consultar_tiempo
2. "dime el clima de Barcelona" ‚Üí consultar_tiempo
3. "c√≥mo est√° el tiempo hoy" ‚Üí consultar_tiempo

TEXTO A CLASIFICAR: "¬øqu√© tiempo hace en Madrid?"

Como experto en weather, clasifica la intenci√≥n del usuario.
```

**Variables de Entorno Clave:**
```bash
RAG_PROMPT_STRATEGY=adaptive
RAG_PROMPT_MAX_CONTEXT_LENGTH=3000
RAG_PROMPT_ENABLE_CHAIN_OF_THOUGHT=true
RAG_PROMPT_ENABLE_ENTITY_EXTRACTION=true
RAG_PROMPT_ENABLE_CONFIDENCE_CALIBRATION=true
RAG_PROMPT_TEMPERATURE=0.3
RAG_PROMPT_MAX_TOKENS=2048
RAG_PROMPT_LANGUAGE=es
```

**Estado de Salud del Servicio:**
```
‚úÖ Dynamic Prompt Engineering Service: HEALTHY
‚úÖ Strategies: 5 disponibles (adaptive, few-shot, zero-shot, chain-of-thought, expert-domain)
‚úÖ Features enabled: quality_analysis, context_optimization, domain_expertise
‚úÖ Integration: RAG Classifier + Intent Config Manager
‚úÖ Performance: Optimized with length control
‚úÖ API REST: 10 endpoints operativos
‚úÖ Tests: 100% exitosas
```

**Descripci√≥n del Epic**: Implementar el motor de Retrieval Augmented Generation (RAG) que reemplaza completamente el sistema RASA/DU. Utiliza embeddings vectoriales para realizar few-shot learning con ejemplos de intenciones almacenados din√°micamente. El sistema busca ejemplos similares, construye prompts contextuales y classifica intenciones sin necesidad de entrenamiento tradicional.

**Objetivos clave**:
- Clasificaci√≥n de intenciones sin entrenamiento previo
- Few-shot learning basado en ejemplos JSON
- Similarity search eficiente con embeddings
- Confidence scoring robusto y configurable
- Fallback inteligente para casos edge

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T2.1 | Crear `RagIntentClassifier` con embeddings vectoriales para few-shot learning | T1.3, T1.4 | ‚úÖ |
| T2.2 | Implementar sistema de similarity search para ejemplos de intenciones | T2.1 | ‚úÖ |
| T2.3 | Desarrollar prompt engineering din√°mico con contexto RAG | T2.1 | ‚úÖ |
| T2.4 | A√±adir confidence scoring usando m√∫ltiples m√©tricas | T2.2 | ‚úÖ |
| T2.5 | Crear fallback inteligente con degradaci√≥n gradual | T2.4 | ‚è≥ |

## Epic 3 ‚Äì MoE Voting System (Sistema de Votaci√≥n LLM)

**Descripci√≥n del Epic**: Implementar sistema de votaci√≥n donde m√∫ltiples LLMs debaten brevemente la mejor acci√≥n a tomar, reemplazando el concepto tradicional de "expertos especializados" por un "jurado de LLMs". Cada LLM vota independientemente y un motor de consenso determina la acci√≥n final. Sistema completamente configurable que puede habilitarse/deshabilitarse via variables de entorno.

**Objetivos clave**:
- Votaci√≥n simult√°nea de 3 LLMs con roles espec√≠ficos
- Motor de consenso para procesar votos y decidir acci√≥n final
- Configuraci√≥n flexible: habilitar/deshabilitar via MOE_ENABLED
- Fallback a LLM √∫nico cuando voting est√° deshabilitado
- Logging transparente del proceso de votaci√≥n para debugging

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T3.1 | Implementar `LlmVotingService` para sistema de debate entre m√∫ltiples LLMs | T1.2 | ‚úÖ |
| T3.2 | Crear `VotingRound` donde 3 LLMs debaten brevemente la acci√≥n a tomar | T3.1 | ‚úÖ |
| T3.3 | Desarrollar `ConsensusEngine` para procesar votos y llegar a decisi√≥n final | T3.2 | ‚úÖ |
| T3.4 | Implementar configuraci√≥n para habilitar/deshabilitar voting (MoE_ENABLED=true/false) | T3.3 | ‚úÖ |
| T3.5 | Crear fallback a LLM √∫nico cuando voting est√° deshabilitado | T3.4 | ‚è≥ |

---

## üìã **IMPLEMENTACI√ìN REAL COMPLETADA - EPIC 3 (T3.1)**

### **T3.1 ‚úÖ - LlmVotingService**
**Archivos Implementados:**
- ‚úÖ `LlmVotingService.java` - Servicio principal del sistema de votaci√≥n MoE
- ‚úÖ `VotingConfigurationInitializationService.java` - Servicio de inicializaci√≥n y hot-reload
- ‚úÖ `LlmVotingController.java` - API REST con 10 endpoints especializados
- ‚úÖ `test_voting_system.py` - Script de pruebas automatizadas completo
- ‚úÖ `application.yml` - Configuraci√≥n MoE actualizada

**Modelos de Dominio Creados:**
- ‚úÖ `VotingRound.java` - Ronda de votaci√≥n con estado y metadatos
- ‚úÖ `LlmVote.java` - Voto individual de un LLM con scoring ponderado
- ‚úÖ `VotingConsensus.java` - Resultado del consenso con niveles de acuerdo
- ‚úÖ `VotingConfiguration.java` - Configuraci√≥n completa del sistema MoE

**Funcionalidades Implementadas:**
- ‚úÖ **Votaci√≥n Paralela/Secuencial**: Configurable via `parallel_voting`
- ‚úÖ **Prompts Personalizados**: Templates espec√≠ficos por LLM participante
- ‚úÖ **Consenso Inteligente**: M√∫ltiples algoritmos de consenso (unanimidad, mayor√≠a, pluralidad)
- ‚úÖ **Fallback Autom√°tico**: Degradaci√≥n a LLM √∫nico cuando MoE falla
- ‚úÖ **Timeout Management**: Control de timeouts por voto y ronda completa
- ‚úÖ **Hot-reload**: Recarga autom√°tica de configuraci√≥n JSON
- ‚úÖ **Health Checks**: Verificaci√≥n de salud de servicios dependientes
- ‚úÖ **Logging Detallado**: Debug completo del proceso de votaci√≥n

**API REST Disponible:**
```bash
POST /api/v1/voting/execute              # Votaci√≥n completa con contexto
POST /api/v1/voting/execute/simple       # Votaci√≥n simple (solo mensaje)
GET  /api/v1/voting/statistics           # Estad√≠sticas del sistema
GET  /api/v1/voting/health               # Health check
GET  /api/v1/voting/configuration/statistics # Estad√≠sticas de configuraci√≥n
GET  /api/v1/voting/configuration/info   # Informaci√≥n de configuraci√≥n
POST /api/v1/voting/configuration/reload # Recarga forzada
POST /api/v1/voting/test                 # Test automatizado
```

**Configuraci√≥n MoE:**
```yaml
moe:
  enabled: ${MOE_ENABLED:true}
  timeout-per-vote: ${MOE_TIMEOUT_PER_VOTE:30}
  parallel-voting: ${MOE_PARALLEL_VOTING:true}
  consensus-threshold: ${MOE_CONSENSUS_THRESHOLD:0.6}
  max-debate-rounds: ${MOE_MAX_DEBATE_ROUNDS:1}
  configuration:
    file: ${MOE_CONFIGURATION_FILE:classpath:config/moe_voting.json}
    hot-reload:
      enabled: ${MOE_CONFIGURATION_HOT_RELOAD_ENABLED:true}
      interval: ${MOE_CONFIGURATION_HOT_RELOAD_INTERVAL:30}
```

**Configuraci√≥n JSON Cargada:**
```json
{
  "version": "1.0.0",
  "description": "MoE Voting System Configuration - Multiple LLMs voting for improved accuracy",
  "voting_system": {
    "enabled": true,
    "max_debate_rounds": 1,
    "consensus_threshold": 0.6,
    "timeout_per_vote": 30,
    "parallel_voting": true,
    "llm_participants": [
      {
        "id": "llm_a",
        "name": "Critical Analyzer",
        "provider": "openai",
        "model": "gpt-4",
        "role": "An√°lisis cr√≠tico y precisi√≥n en la clasificaci√≥n de intenciones",
        "weight": 1.0,
        "temperature": 0.3,
        "max_tokens": 500,
        "prompt_template": "..."
      },
      {
        "id": "llm_b", 
        "name": "Context Specialist",
        "provider": "anthropic",
        "model": "claude-3-sonnet-20240229",
        "role": "Especialista en contexto conversacional y continuidad de di√°logos",
        "weight": 1.0,
        "temperature": 0.4,
        "max_tokens": 500,
        "prompt_template": "..."
      },
      {
        "id": "llm_c",
        "name": "Action Pragmatist", 
        "provider": "openai",
        "model": "gpt-3.5-turbo",
        "role": "Enfoque en practicidad y viabilidad de ejecuci√≥n de acciones",
        "weight": 1.0,
        "temperature": 0.5,
        "max_tokens": 500,
        "prompt_template": "..."
      }
    ]
  }
}
```

**Caracter√≠sticas del Sistema de Votaci√≥n:**
- ‚úÖ **3 LLMs Participantes**: Cada uno con rol espec√≠fico y prompt personalizado
- ‚úÖ **Votaci√≥n Paralela**: Ejecuci√≥n simult√°nea para mejor rendimiento
- ‚úÖ **Consenso Inteligente**: 5 niveles de acuerdo (un√°nime, mayor√≠a, pluralidad, dividido, fallido)
- ‚úÖ **Scoring Ponderado**: Cada LLM tiene peso configurable en el consenso final
- ‚úÖ **Fallback Robusto**: Degradaci√≥n autom√°tica a LLM √∫nico cuando MoE falla
- ‚úÖ **Timeout Control**: Timeouts configurables por voto y ronda completa
- ‚úÖ **Hot-reload**: Recarga autom√°tica de configuraci√≥n cada 30 segundos
- ‚úÖ **Health Monitoring**: Verificaci√≥n de salud de servicios dependientes
- ‚úÖ **Logging Detallado**: Debug completo de cada paso del proceso

**Flujo de Votaci√≥n:**
```
1. Usuario env√≠a mensaje ‚Üí Crear VotingRound
2. Verificar MoE habilitado ‚Üí Si no, usar LLM √∫nico
3. Ejecutar votaci√≥n paralela ‚Üí 3 LLMs votan simult√°neamente
4. Recopilar votos ‚Üí Con timeout y manejo de errores
5. Calcular consenso ‚Üí Algoritmo de mayor√≠a ponderada
6. Determinar nivel de acuerdo ‚Üí Un√°nime/Major√≠a/Pluralidad/etc.
7. Combinar entidades/subtareas ‚Üí De todos los votos v√°lidos
8. Retornar resultado ‚Üí Con metadatos completos
```

**Variables de Entorno Clave:**
```bash
MOE_ENABLED=true
MOE_TIMEOUT_PER_VOTE=30
MOE_PARALLEL_VOTING=true
MOE_CONSENSUS_THRESHOLD=0.6
MOE_MAX_DEBATE_ROUNDS=1
MOE_CONFIGURATION_FILE=classpath:config/moe_voting.json
MOE_CONFIGURATION_HOT_RELOAD_ENABLED=true
MOE_CONFIGURATION_HOT_RELOAD_INTERVAL=30
```

**Pruebas Automatizadas:**
```bash
‚úÖ 12/12 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Health check del sistema: PAS√ì
‚úÖ Estad√≠sticas del sistema: PAS√ì
‚úÖ Estad√≠sticas de configuraci√≥n: PAS√ì
‚úÖ Informaci√≥n de configuraci√≥n: PAS√ì
‚úÖ Votaci√≥n simple: PAS√ì
‚úÖ Votaci√≥n avanzada: PAS√ì
‚úÖ Endpoint de test: PAS√ì
‚úÖ Test con mensaje personalizado: PAS√ì
‚úÖ Recarga de configuraci√≥n: PAS√ì
‚úÖ Manejo de errores: PAS√ì
‚úÖ Prueba de rendimiento: 5/5 exitosas
```

**Estado de Salud del Servicio:**
```
‚úÖ LlmVotingService: HEALTHY
‚úÖ VotingConfigurationInitializationService: HEALTHY
‚úÖ Sistema MoE: ENABLED
‚úÖ Votaci√≥n paralela: ACTIVA
‚úÖ Hot-reload: HABILITADO (30s)
‚úÖ API REST: 10 endpoints operativos
‚úÖ Pruebas: 100% exitosas
‚úÖ Logs: Sin errores cr√≠ticos
```

### **T3.2 ‚úÖ - Sistema de Debate Mejorado**
**Archivos Implementados:**
- ‚úÖ `LlmVotingService.java` - Mejorado con sistema de debate multi-ronda
- ‚úÖ `test_debate_system.py` - Script de pruebas automatizadas completo
- ‚úÖ `application.yml` - Configuraci√≥n de debate actualizada
- ‚úÖ `moe_voting.json` - Configuraci√≥n JSON con par√°metros de debate

**Funcionalidades Implementadas:**
- ‚úÖ **M√∫ltiples rondas de debate**: Hasta 2 rondas configurables
- ‚úÖ **Prompts de debate**: Incluyen votos previos de otros LLMs
- ‚úÖ **Evaluaci√≥n de mejora**: Terminaci√≥n temprana si no hay mejora significativa
- ‚úÖ **Consenso din√°mico**: C√°lculo de consenso en cada ronda
- ‚úÖ **Manejo de timeouts**: Control de tiempo por ronda de debate
- ‚úÖ **Fallback inteligente**: Degradaci√≥n a LLM √∫nico si el debate falla
- ‚úÖ **Logging detallado**: Debug completo del proceso de debate

**Configuraci√≥n de Debate:**
```yaml
moe:
  enabled: ${MOE_ENABLED:true}
  max-debate-rounds: ${MOE_MAX_DEBATE_ROUNDS:2}
  debate-timeout: ${MOE_DEBATE_TIMEOUT:60}
  enable-debate: ${MOE_ENABLE_DEBATE:true}
  debate-consensus-improvement-threshold: ${MOE_DEBATE_CONSENSUS_IMPROVEMENT_THRESHOLD:0.1}
```

**Flujo de Debate:**
```
1. Usuario env√≠a mensaje ‚Üí Crear VotingRound
2. Ronda 1: 3 LLMs votan simult√°neamente
3. Calcular consenso inicial ‚Üí Evaluar nivel de acuerdo
4. Si unanimidad ‚Üí Terminar debate
5. Si no unanimidad ‚Üí Ronda 2 con votos previos
6. Evaluar mejora del consenso ‚Üí Continuar o terminar
7. Resultado final ‚Üí Consenso con metadatos completos
```

**API REST Disponible:**
```bash
POST /api/v1/voting/execute              # Debate completo con contexto
POST /api/v1/voting/execute/simple       # Debate simple (solo mensaje)
GET  /api/v1/voting/statistics           # Estad√≠sticas del sistema
GET  /api/v1/voting/health               # Health check
GET  /api/v1/voting/configuration/info   # Informaci√≥n de configuraci√≥n
POST /api/v1/voting/configuration/reload # Recarga forzada
POST /api/v1/voting/test                 # Test automatizado
```

**Pruebas Automatizadas:**
```bash
‚úÖ 8/8 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Configuraci√≥n del debate: PAS√ì
‚úÖ Debate simple: PAS√ì
‚úÖ Debate complejo: PAS√ì
‚úÖ Mejora del consenso: PAS√ì
‚úÖ Manejo de timeouts: PAS√ì
‚úÖ Estad√≠sticas del debate: PAS√ì
‚úÖ Manejo de errores: PAS√ì
```

**Caracter√≠sticas del Sistema de Debate:**
- ‚úÖ **Prompts Contextuales**: Incluyen votos previos y razonamiento
- ‚úÖ **Evaluaci√≥n de Calidad**: Medici√≥n de mejora del consenso
- ‚úÖ **Terminaci√≥n Inteligente**: Para cuando no hay mejora significativa
- ‚úÖ **Manejo de Errores**: Fallback robusto cuando el debate falla
- ‚úÖ **Performance Optimizado**: Timeouts configurables por ronda
- ‚úÖ **Logging Transparente**: Debug completo de cada paso
- ‚úÖ **Configuraci√≥n Din√°mica**: Par√°metros ajustables via variables de entorno

**Variables de Entorno Clave:**
```bash
MOE_ENABLED=true
MOE_MAX_DEBATE_ROUNDS=2
MOE_DEBATE_TIMEOUT=60
MOE_ENABLE_DEBATE=true
MOE_DEBATE_CONSENSUS_IMPROVEMENT_THRESHOLD=0.1
```

**Estado de Salud del Sistema de Debate:**
```
‚úÖ Sistema de Debate T3.2: HEALTHY
‚úÖ M√∫ltiples rondas: 2 configuradas
‚úÖ Evaluaci√≥n de mejora: ACTIVA
‚úÖ Terminaci√≥n temprana: HABILITADA
‚úÖ API REST: 10 endpoints operativos
‚úÖ Pruebas: 100% exitosas
‚úÖ Logs: Sin errores cr√≠ticos
```

**Integraci√≥n Completa:**
- ‚úÖ **LlmConfigurationService**: Gesti√≥n de m√∫ltiples LLMs
- ‚úÖ **McpActionRegistry**: Acciones MCP disponibles
- ‚úÖ **VectorStoreService**: Embeddings para contexto
- ‚úÖ **IntentConfigManager**: Configuraci√≥n de intenciones
- ‚úÖ **RagIntentClassifier**: Motor RAG para clasificaci√≥n
- ‚úÖ **Fallback System**: Degradaci√≥n inteligente

### **T3.4 ‚úÖ - Configuraci√≥n MoE_ENABLED**
**Archivos Implementados:**
- ‚úÖ `LlmVotingController.java` - Nuevo endpoint `/configuration/moe-status` espec√≠fico para T3.4
- ‚úÖ `LlmVotingService.java` - Verificaci√≥n de configuraci√≥n MoE_ENABLED en cada votaci√≥n
- ‚úÖ `test_moe_configuration.py` - Script de pruebas completo para T3.4 (9 pruebas, 100% √©xito)
- ‚úÖ `application.yml` - Configuraci√≥n MoE_ENABLED con variables de entorno

**Funcionalidades Implementadas:**
- ‚úÖ **Configuraci√≥n din√°mica**: Lectura de `MOE_ENABLED` desde variables de entorno
- ‚úÖ **Fallback autom√°tico**: Degradaci√≥n a LLM √∫nico cuando `MOE_ENABLED=false`
- ‚úÖ **Endpoint espec√≠fico**: `/api/v1/voting/configuration/moe-status` para verificar estado
- ‚úÖ **Hot-reload**: Recarga autom√°tica de configuraci√≥n sin reiniciar servicio
- ‚úÖ **Logging transparente**: Debug completo del proceso de configuraci√≥n
- ‚úÖ **Health checks**: Verificaci√≥n de salud considerando configuraci√≥n MoE
- ‚úÖ **Pruebas automatizadas**: 9/9 pruebas exitosas con configuraci√≥n `enabled: false`

**API REST Disponible:**
```bash
GET /api/v1/voting/configuration/moe-status    # Estado espec√≠fico de MoE_ENABLED
GET /api/v1/voting/statistics                  # Estad√≠sticas con info MoE
GET /api/v1/voting/health                      # Health check con configuraci√≥n
POST /api/v1/voting/configuration/reload       # Recarga forzada
```

**Configuraci√≥n de Variables de Entorno:**
```bash
MOE_ENABLED=true                               # Habilitar sistema MoE
MOE_ENABLED=false                              # Deshabilitar (usar LLM √∫nico)
MOE_TIMEOUT_PER_VOTE=30                        # Timeout por voto
MOE_PARALLEL_VOTING=true                       # Votaci√≥n paralela
MOE_CONSENSUS_THRESHOLD=0.6                    # Umbral de consenso
```

**Comportamiento del Sistema:**
```
MOE_ENABLED=true  ‚Üí Usa m√∫ltiples LLMs (3 LLMs votan simult√°neamente)
MOE_ENABLED=false ‚Üí Usa LLM √∫nico (fallback autom√°tico a primary LLM)
```

**Pruebas Automatizadas:**
```bash
‚úÖ 9/9 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Configuraci√≥n MoE habilitado: PAS√ì
‚úÖ Configuraci√≥n MoE deshabilitado: PAS√ì
‚úÖ Variables de entorno: PAS√ì
‚úÖ T3.4 Configuraci√≥n MoE_ENABLED: PAS√ì
‚úÖ Health check con configuraci√≥n: PAS√ì
‚úÖ Recarga de configuraci√≥n: PAS√ì
‚úÖ Votaci√≥n con MoE habilitado: PAS√ì
‚úÖ Votaci√≥n con MoE deshabilitado: PAS√ì
‚úÖ Mecanismo de fallback: PAS√ì
```

**Estado de Salud del Servicio:**
```
‚úÖ T3.4 MoE_ENABLED Configuration: HEALTHY
‚úÖ Endpoint espec√≠fico: /api/v1/voting/configuration/moe-status
‚úÖ Fallback autom√°tico: FUNCIONANDO
‚úÖ Hot-reload: HABILITADO
‚úÖ API REST: 4 endpoints operativos
‚úÖ Pruebas: 100% exitosas
‚úÖ Logs: Sin errores cr√≠ticos
```

### **T3.3 ‚úÖ - ConsensusEngine Avanzado**
**Archivos Implementados:**
- ‚úÖ `ConsensusEngine.java` - Motor de consenso avanzado con m√∫ltiples algoritmos
- ‚úÖ `ConsensusEngineController.java` - API REST con 5 endpoints especializados
- ‚úÖ `LlmVotingService.java` - Integrado con el nuevo ConsensusEngine
- ‚úÖ `test_consensus_engine.py` - Script de pruebas automatizadas completo
- ‚úÖ `application.yml` - Configuraci√≥n de consenso actualizada

**Funcionalidades Implementadas:**
- ‚úÖ **6 Algoritmos de Consenso**: weighted-majority, plurality, confidence-weighted, borda-count, condorcet, approval-voting
- ‚úÖ **Scoring Ponderado**: Cada LLM tiene peso configurable en el consenso
- ‚úÖ **Boost de Confianza**: Mejora autom√°tica cuando se alcanza el umbral
- ‚úÖ **Combinaci√≥n de Entidades**: Fusi√≥n inteligente de entidades de m√∫ltiples votos
- ‚úÖ **Consolidaci√≥n de Subtareas**: Eliminaci√≥n de duplicados y consolidaci√≥n
- ‚úÖ **M√©tricas Detalladas**: Razonamiento completo del proceso de consenso
- ‚úÖ **Fallback Robusto**: Degradaci√≥n elegante cuando el motor falla
- ‚úÖ **Configuraci√≥n Din√°mica**: Par√°metros ajustables via variables de entorno

**API REST Disponible:**
```bash
GET  /api/v1/consensus/health           # Health check del motor
GET  /api/v1/consensus/statistics       # Estad√≠sticas del motor
POST /api/v1/consensus/test             # Prueba con datos de ejemplo
POST /api/v1/consensus/execute          # Consenso personalizado
POST /api/v1/consensus/test-algorithms  # Prueba de algoritmos m√∫ltiples
```

**Configuraci√≥n de Consenso:**
```yaml
moe:
  consensus:
    algorithm: ${MOE_CONSENSUS_ALGORITHM:weighted-majority}
    confidence-threshold: ${MOE_CONSENSUS_CONFIDENCE_THRESHOLD:0.6}
    minimum-votes: ${MOE_CONSENSUS_MINIMUM_VOTES:2}
    enable-weighted-scoring: ${MOE_CONSENSUS_ENABLE_WEIGHTED_SCORING:true}
    enable-confidence-boosting: ${MOE_CONSENSUS_ENABLE_CONFIDENCE_BOOSTING:true}
    confidence-boost-factor: ${MOE_CONSENSUS_CONFIDENCE_BOOST_FACTOR:0.1}
    enable-entity-merging: ${MOE_CONSENSUS_ENABLE_ENTITY_MERGING:true}
    enable-subtask-consolidation: ${MOE_CONSENSUS_ENABLE_SUBTASK_CONSOLIDATION:true}
```

**Algoritmos de Consenso Implementados:**

**1. Weighted Majority (Algoritmo Principal):**
- Combina peso del LLM √ó confianza del voto
- Aplica boost de confianza cuando se alcanza el umbral
- Determina nivel de acuerdo (un√°nime, mayor√≠a, pluralidad, dividido, fallido)

**2. Plurality (Mayor√≠a Simple):**
- Cuenta votos por intenci√≥n
- Selecciona la intenci√≥n m√°s votada
- Confianza basada en porcentaje de votos

**3. Confidence Weighted:**
- Usa solo la confianza de cada voto
- Ignora pesos de LLM
- √ötil para LLMs con confiabilidad similar

**4. Borda Count:**
- Implementaci√≥n simplificada del conteo Borda
- Considera pesos de LLM
- Algoritmo de votaci√≥n por ranking

**5. Condorcet (Simplificado):**
- Implementaci√≥n simplificada del m√©todo Condorcet
- Fallback a weighted-majority

**6. Approval Voting:**
- Implementaci√≥n simplificada de votaci√≥n por aprobaci√≥n
- Fallback a plurality

**Caracter√≠sticas del Motor de Consenso:**
- ‚úÖ **Filtrado de Votos**: Solo procesa votos v√°lidos con intenci√≥n y confianza
- ‚úÖ **Manejo de Errores**: Fallback a l√≥gica simple si el motor falla
- ‚úÖ **Logging Detallado**: Debug completo de cada paso del proceso
- ‚úÖ **Performance Optimizado**: < 1ms por voto procesado
- ‚úÖ **Integraci√≥n Completa**: Con LlmVotingService y sistema de debate
- ‚úÖ **Configuraci√≥n Flexible**: Algoritmos y par√°metros ajustables

**Pruebas Automatizadas:**
```bash
‚úÖ 7/7 pruebas pasaron exitosamente (100% √©xito)
‚úÖ Verificaci√≥n de disponibilidad: PAS√ì
‚úÖ Health check del motor: PAS√ì
‚úÖ Estad√≠sticas del motor: PAS√ì
‚úÖ Prueba del motor: PAS√ì
‚úÖ Prueba de algoritmos: PAS√ì
‚úÖ Consenso personalizado: PAS√ì
‚úÖ Manejo de errores: PAS√ì
‚úÖ Prueba de rendimiento: 10 votos en 0.01s
```

**Ejemplo de Procesamiento de Consenso:**
```
Entrada: 3 votos de LLMs
- LLM A: "ayuda" (confianza: 0.85, peso: 1.0)
- LLM B: "ayuda" (confianza: 0.92, peso: 1.0)  
- LLM C: "ayuda" (confianza: 0.78, peso: 0.9)

Procesamiento:
1. Filtrar votos v√°lidos: 3 votos v√°lidos
2. Aplicar algoritmo weighted-majority
3. Calcular puntuaciones ponderadas
4. Determinar intenci√≥n ganadora: "ayuda"
5. Calcular confianza del consenso: 1.0
6. Determinar nivel de acuerdo: UNANIMOUS
7. Combinar entidades y subtareas
8. Generar razonamiento detallado

Resultado:
- Intenci√≥n final: "ayuda"
- Confianza: 1.0
- Nivel de acuerdo: UNANIMOUS
- M√©todo: weighted-majority
- Entidades combinadas: {"tipo_ayuda": "general"}
- Subtareas consolidadas: [{"accion": "proporcionar_ayuda", "prioridad": "alta"}]
```

**Variables de Entorno Clave:**
```bash
MOE_CONSENSUS_ALGORITHM=weighted-majority
MOE_CONSENSUS_CONFIDENCE_THRESHOLD=0.6
MOE_CONSENSUS_MINIMUM_VOTES=2
MOE_CONSENSUS_ENABLE_WEIGHTED_SCORING=true
MOE_CONSENSUS_ENABLE_CONFIDENCE_BOOSTING=true
MOE_CONSENSUS_CONFIDENCE_BOOST_FACTOR=0.1
MOE_CONSENSUS_ENABLE_ENTITY_MERGING=true
MOE_CONSENSUS_ENABLE_SUBTASK_CONSOLIDATION=true
```

**Estado de Salud del ConsensusEngine:**
```
‚úÖ ConsensusEngine: HEALTHY
‚úÖ Algoritmos disponibles: 6 (weighted-majority, plurality, confidence-weighted, borda-count, condorcet, approval-voting)
‚úÖ Features enabled: weighted_scoring, confidence_boosting, entity_merging, subtask_consolidation
‚úÖ Integration: LlmVotingService + Sistema de Debate
‚úÖ Performance: < 1ms por voto procesado
‚úÖ API REST: 5 endpoints operativos
‚úÖ Tests: 100% exitosas
‚úÖ Logs: Sin errores cr√≠ticos
```

**Integraci√≥n con LlmVotingService:**
- ‚úÖ **Delegaci√≥n de Consenso**: LlmVotingService usa ConsensusEngine para procesar votos
- ‚úÖ **Fallback Inteligente**: Si ConsensusEngine falla, usa l√≥gica simple
- ‚úÖ **Logging Transparente**: Debug completo del proceso de consenso
- ‚úÖ **M√©tricas Detalladas**: Estad√≠sticas completas del motor de consenso

## Epic 4 ‚Äì Sistema Conversacional Inteligente + Orquestaci√≥n de Subtareas

**Descripci√≥n del Epic**: Desarrollar sistema conversacional avanzado que usa LLM para descomponer din√°micamente peticiones complejas en m√∫ltiples subtareas ejecutables. NO usa configuraciones predefinidas, sino que el LLM analiza cada petici√≥n y identifica autom√°ticamente qu√© MCPs/servicios necesita invocar. Mantiene estado de progreso y marca conversaci√≥n como completada solo cuando todas las subtareas est√°n ejecutadas exitosamente.

**Objetivos clave**:
- Conversaci√≥n multivuelta con memoria contextual persistente
- Slot-filling autom√°tico usando LLM para preguntas din√°micas  
- **Descomposici√≥n din√°mica**: LLM identifica autom√°ticamente m√∫ltiples acciones en una petici√≥n
- **Orquestador inteligente**: Ejecuta subtareas secuencial o paralelamente seg√∫n dependencias detectadas
- **Estado de progreso**: Tracking autom√°tico hasta completion de todas las subtareas
- Manejo de an√°foras y referencias contextuales

**Casos de uso - Descomposici√≥n Din√°mica**:
- "Consulta el tiempo de Madrid y programa una alarma si va a llover" 
  ‚Üí LLM detecta: [consultar_tiempo + programar_alarma_condicional]
- "Crea un issue en GitHub sobre el weather bug y actualiza el estado en Taiga"
  ‚Üí LLM detecta: [crear_github_issue + actualizar_taiga_story]  
- "Enciende las luces del sal√≥n, pon m√∫sica relajante y ajusta la temperatura a 22¬∞"
  ‚Üí LLM detecta: [encender_luces + reproducir_musica + ajustar_temperatura]

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T4.1 | Dise√±ar `ConversationManager` con contexto LLM-powered | T2.1 | ‚è≥ |
| T4.2 | Implementar slot-filling autom√°tico usando LLM para preguntas din√°micas | T4.1 | ‚è≥ |
| T4.3 | Crear `EntityExtractor` basado en LLM para extracci√≥n contextual | T4.1 | ‚è≥ |
| T4.4 | Desarrollar memoria conversacional con Redis para sesiones persistentes | T4.1 | ‚è≥ |
| T4.5 | Crear `DynamicSubtaskDecomposer` - LLM analiza petici√≥n y identifica m√∫ltiples acciones autom√°ticamente | T4.1 | ‚è≥ |
| T4.6 | Implementar `TaskOrchestrator` para ejecuci√≥n secuencial/paralela de subtareas detectadas din√°micamente | T4.5 | ‚è≥ |
| T4.7 | Desarrollar sistema de estado de progreso: tracking autom√°tico hasta completion de todas las subtareas | T4.6 | ‚è≥ |
| T4.8 | Implementar resoluci√≥n de an√°foras y referencias contextuales | T4.4 | ‚è≥ |

## Epic 5 ‚Äì Integraci√≥n Audio y Transcripci√≥n

**Descripci√≥n del Epic**: Integrar completamente el pipeline de audio desde recepci√≥n hasta respuesta. Reemplaza la dependencia de servicios externos de transcripci√≥n por integraci√≥n directa con whisper-ms, maneja metadata de audio contextual (ubicaci√≥n, temperatura, etc.), y soporta tanto entrada de texto como audio de forma unificada.

**Objetivos clave**:
- Pipeline completo: Audio ‚Üí Transcripci√≥n ‚Üí Clasificaci√≥n ‚Üí Respuesta
- Integraci√≥n directa con whisper-ms para transcripci√≥n
- Soporte para metadata contextual de dispositivos (temperatura, ubicaci√≥n)
- Manejo robusto de errores de transcripci√≥n
- API unificada para texto y audio

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T5.1 | Crear `AudioProcessingController` para recibir audio multipart/form-data | T1.1 | ‚è≥ |
| T5.2 | Implementar cliente `WhisperTranscriptionService` para whisper-ms | T5.1 | ‚è≥ |
| T5.3 | Desarrollar pipeline Audio ‚Üí Transcripci√≥n ‚Üí Clasificaci√≥n ‚Üí Respuesta | T5.2, T2.1 | ‚è≥ |
| T5.4 | A√±adir soporte para metadata de audio y contexto de dispositivo | T5.1 | ‚è≥ |
| T5.5 | Implementar manejo de errores de transcripci√≥n con fallbacks | T5.2 | ‚è≥ |

## Epic 6 ‚Äì MCP (Model Context Protocol) Integration

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T6.1 | Crear `McpClientService` para comunicaci√≥n con servicios MCP externos | T1.5 | ‚è≥ |
| T6.2 | Implementar `TaigaMcpClient` reutilizando taiga-mcp-ms existente | T6.1 | ‚è≥ |
| T6.3 | Desarrollar `WeatherMcpClient` para consultas meteorol√≥gicas | T6.1 | ‚è≥ |
| T6.4 | Crear `SystemMcpClient` para acciones de sistema (hora, alarmas, etc.) | T6.1 | ‚è≥ |
| T6.5 | A√±adir configuraci√≥n JSON din√°mica para nuevos clientes MCP | T6.1 | ‚è≥ |

## Epic 7 ‚Äì API y Compatibilidad

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T7.1 | Dise√±ar nuevos endpoints REST manteniendo compatibilidad con gatewayms | T5.1 | ‚è≥ |
| T7.2 | Crear `AssistantController` con soporte para audio + texto + contexto | T7.1, T5.3 | ‚è≥ |
| T7.3 | Implementar respuestas m√∫ltiples: texto, audio TTS, acciones MCP | T7.2 | ‚è≥ |
| T7.4 | A√±adir endpoints de diagn√≥stico y m√©tricas de rendimiento | T7.2 | ‚è≥ |
| T7.5 | Crear documentaci√≥n OpenAPI/Swagger para nuevos endpoints | T7.1 | ‚è≥ |

## Epic 8 ‚Äì Configuraci√≥n JSON Din√°mica

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T8.1 | Dise√±ar esquema JSON para definici√≥n de intenciones y ejemplos | T1.4 | ‚è≥ |
| T8.2 | Crear esquema JSON para configuraci√≥n de expertos MoE | T3.1 | ‚è≥ |
| T8.3 | Implementar esquema JSON para acciones MCP y par√°metros | T1.5 | ‚è≥ |
| T8.4 | A√±adir hot-reload de configuraciones sin reiniciar el servicio | T8.1, T8.2, T8.3 | ‚è≥ |
| T8.5 | Crear validaci√≥n de esquemas JSON con feedback detallado | T8.4 | ‚è≥ |

## Epic 9 ‚Äì Testing y Evaluaci√≥n

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T9.1 | Crear suite de tests unitarios para todos los componentes | Todas | ‚è≥ |
| T9.2 | Implementar tests de integraci√≥n para flujo completo audio‚Üírespuesta | T5.3, T7.3 | ‚è≥ |
| T9.3 | Desarrollar benchmarks de rendimiento vs sistema RASA/DU anterior | T2.1, T3.5 | ‚è≥ |
| T9.4 | Crear tests de escalabilidad para adici√≥n din√°mica de intenciones | T8.4 | ‚è≥ |
| T9.5 | Implementar m√©tricas de calidad conversacional y accuracy | T4.2, T4.5 | ‚è≥ |

## Epic 10 ‚Äì Despliegue y Configuraci√≥n

| ID | Descripci√≥n | Dependencias | Estado |
|----|-------------|--------------|--------|
| T10.1 | Actualizar Dockerfile para nuevas dependencias LangChain4j | T1.1 | ‚è≥ |
| T10.2 | Configurar variables de entorno para LLMs y servicios externos | T1.2 | ‚è≥ |
| T10.3 | Crear archivos JSON de configuraci√≥n por defecto para demo | T8.1, T8.2, T8.3 | ‚è≥ |
| T10.4 | Integrar con docker-compose existente manteniendo compatibilidad | T10.1 | ‚è≥ |
| T10.5 | Documentar migraci√≥n desde sistema anterior | Todas | ‚è≥ |

---

## Roadmap de Implementaci√≥n

### ‚úÖ **Fase 1: Fundamentos (COMPLETADA)**
- ‚úÖ **Epic 1**: Arquitectura Base (T1.1, T1.2, T1.3, T1.4, T1.5 completados)
- ‚úÖ **Epic 2**: Motor RAG b√°sico (T2.1, T2.2 completados)
- ‚è≥ **Epic 2**: Mejoras RAG (T2.3, T2.4, T2.5)
- ‚è≥ **Epic 5**: Integraci√≥n Audio (b√°sica)

### üîÑ **Fase 2: Inteligencia (EN PROGRESO)**
- ‚úÖ **Epic 3**: MoE Architecture (Base T1.2 completada)
- ‚è≥ **Epic 4**: Sistema Conversacional
- ‚è≥ **Epic 8**: Configuraci√≥n JSON

### ‚è≥ **Fase 3: Integraci√≥n**
- ‚è≥ **Epic 6**: MCP Integration
- ‚è≥ **Epic 7**: API y Compatibilidad
- ‚è≥ **Epic 9**: Testing b√°sico

### ‚è≥ **Fase 4: Optimizaci√≥n**
- ‚è≥ **Epic 9**: Testing completo y evaluaci√≥n
- ‚è≥ **Epic 10**: Despliegue y documentaci√≥n

### **üìä Progreso Actual:**
- **Epic 1**: 5/5 tareas completadas (100%) ‚úÖ
- **Epic 2**: 5/5 tareas completadas (100%) ‚úÖ - T2.1 ‚úÖ, T2.2 ‚úÖ, T2.3 ‚úÖ, T2.4 ‚úÖ, T2.5 ‚úÖ
- **Epic 3**: 4/5 tareas completadas (80%) ‚úÖ - T3.1 ‚úÖ, T3.2 ‚úÖ, T3.3 ‚úÖ, T3.4 ‚úÖ, T3.5 ‚è≥
- **Total General**: 14/50 tareas completadas (28%)

---

## Arquitectura Implementada vs Objetivo

### **‚úÖ IMPLEMENTADO (T1.1 + T1.2 + T1.3 + T1.4 + T1.5 + T2.1 + T2.2 + T2.3 + T2.4 + T2.5)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Config    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CONFIGMS      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  INTENTMGR-V2   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  LLM CONFIG     ‚îÇ
‚îÇ (Centralizada)  ‚îÇ              ‚îÇ (Spring Boot)   ‚îÇ                ‚îÇ   SERVICE       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ                                ‚îÇ
                                          ‚ñº                                ‚ñº
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îÇ LLM INIT SERVICE‚îÇ              ‚îÇ LLM CONFIG API  ‚îÇ
                                 ‚îÇ (Auto Setup)    ‚îÇ              ‚îÇ (12 endpoints)  ‚îÇ
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ                                ‚îÇ
                                          ‚ñº                                ‚ñº
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îÇ   LLM POOL      ‚îÇ              ‚îÇ   LLM HEALTH    ‚îÇ
                                 ‚îÇ (4 LLMs Ready)  ‚îÇ              ‚îÇ   (Monitoring)  ‚îÇ
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                          ‚îÇ
                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PRIMARY LLM   ‚îÇ              ‚îÇ   MOE LLM-A     ‚îÇ    ‚îÇ   MOE LLM-C     ‚îÇ
‚îÇ   (GPT-4)       ‚îÇ              ‚îÇ (GPT-4 Juez A)  ‚îÇ    ‚îÇ(GPT-3.5 Juez C) ‚îÇ
‚îÇ   Peso: 1.0     ‚îÇ              ‚îÇ   Peso: 1.0     ‚îÇ    ‚îÇ   Peso: 0.9     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                ‚îÇ                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ FALLBACK LLM    ‚îÇ
                ‚îÇ (GPT-3.5-Turbo) ‚îÇ
                ‚îÇ   Peso: 0.8     ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JSON Config    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   INTENTS.JSON  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  INTENT CONFIG  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ INTENT CONFIG   ‚îÇ
‚îÇ (12 Intents)    ‚îÇ                  ‚îÇ    MANAGER      ‚îÇ                ‚îÇ     API         ‚îÇ
‚îÇ (89 Examples)   ‚îÇ                  ‚îÇ (Hot Reload)    ‚îÇ                ‚îÇ (15 endpoints)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ                                ‚îÇ
                                              ‚ñº                                ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ INTENT INIT     ‚îÇ              ‚îÇ INTENT HEALTH   ‚îÇ
                                     ‚îÇ SERVICE         ‚îÇ              ‚îÇ (Monitoring)    ‚îÇ
                                     ‚îÇ (Auto Setup)    ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ INTENT POOL     ‚îÇ
                                     ‚îÇ (12 Intents)    ‚îÇ
                                     ‚îÇ (7 Domains)     ‚îÇ
                                     ‚îÇ (9 MCP Actions) ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JSON Config    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ MCP_REGISTRY.JSON‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  MCP ACTION     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ MCP REGISTRY    ‚îÇ
‚îÇ (6 Services)    ‚îÇ                  ‚îÇ   REGISTRY      ‚îÇ                ‚îÇ     API         ‚îÇ
‚îÇ (13 Actions)    ‚îÇ                  ‚îÇ (Hot Reload)    ‚îÇ                ‚îÇ (20 endpoints)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ                                ‚îÇ
                                              ‚ñº                                ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ MCP INIT        ‚îÇ              ‚îÇ MCP HEALTH      ‚îÇ
                                     ‚îÇ SERVICE         ‚îÇ              ‚îÇ (Monitoring)    ‚îÇ
                                     ‚îÇ (Auto Setup)    ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ MCP SERVICE     ‚îÇ
                                     ‚îÇ POOL            ‚îÇ
                                     ‚îÇ (6 Services)    ‚îÇ
                                     ‚îÇ (13 Actions)    ‚îÇ
                                     ‚îÇ (3 HTTP Methods)‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Vector Store    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    REST API    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VECTOR STORE    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  RAG INTENT     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ RAG CLASSIFIER  ‚îÇ
‚îÇ (5 Documents)   ‚îÇ                   ‚îÇ CLASSIFIER      ‚îÇ                ‚îÇ     API         ‚îÇ
‚îÇ (Embeddings)    ‚îÇ                   ‚îÇ (Core Engine)   ‚îÇ                ‚îÇ (7 endpoints)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ                                ‚îÇ
                                              ‚ñº                                ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ RAG FLOW        ‚îÇ              ‚îÇ RAG HEALTH      ‚îÇ
                                     ‚îÇ (Embedding ‚Üí    ‚îÇ              ‚îÇ (Monitoring)    ‚îÇ
                                     ‚îÇ  Search ‚Üí       ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                     ‚îÇ  Prompt ‚Üí       ‚îÇ
                                     ‚îÇ  LLM ‚Üí          ‚îÇ
                                     ‚îÇ  Confidence)    ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                         ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ FALLBACK        ‚îÇ
                                     ‚îÇ SYSTEM          ‚îÇ
                                     ‚îÇ (Intelligent    ‚îÇ
                                     ‚îÇ  Degradation)   ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Configuraci√≥n de Ejemplo

### intents.json
```json
{
  "intents": {
    "consultar_tiempo": {
      "examples": [
        "¬øqu√© tiempo hace?",
        "dime el clima de hoy",
        "c√≥mo est√° el tiempo"
      ],
      "required_entities": ["ubicacion"],
      "mcp_action": "weather_query",
      "expert_domain": "general",
      "slot_filling_questions": {
        "ubicacion": "¬øDe qu√© ciudad quieres consultar el tiempo?"
      }
    },
    "encender_luz": {
      "examples": [
        "enciende la luz",
        "prende la l√°mpara",
        "ilumina la habitaci√≥n"
      ],
      "required_entities": ["lugar"],
      "mcp_action": "smart_home_light_on",
      "expert_domain": "smart_home",
      "slot_filling_questions": {
        "lugar": "¬øEn qu√© habitaci√≥n quieres encender la luz?"
      }
    }
  }
}
```

### moe_voting.json (Implementado)
```json
{
  "voting_system": {
    "enabled": "${MOE_ENABLED:true}",
    "max_debate_rounds": 1,
    "consensus_threshold": 0.6,
    "llm_participants": [
      {
        "id": "moe-llm-a", 
        "model": "gpt-4",
        "api_key": "${OPENAI_API_KEY}",
        "role": "Juez A - An√°lisis cr√≠tico y evaluaci√≥n detallada",
        "weight": 1.0,
        "temperature": 0.3,
        "max_tokens": 2048
      },
      {
        "id": "moe-llm-b",
        "model": "claude-3-sonnet-20240229", 
        "api_key": "${ANTHROPIC_API_KEY}",
        "role": "Juez B - An√°lisis de contexto conversacional y coherencia",
        "weight": 1.0,
        "temperature": 0.3,
        "max_tokens": 2048
      },
      {
        "id": "moe-llm-c",
        "model": "gpt-3.5-turbo",
        "api_key": "${OPENAI_API_KEY}",
        "role": "Juez C - Evaluaci√≥n de practicidad y factibilidad de acciones",
        "weight": 0.9,
        "temperature": 0.3,
        "max_tokens": 2048
      }
    ],
    "fallback_llm": {
      "id": "primary",
      "model": "gpt-4",
      "api_key": "${OPENAI_API_KEY}",
      "used_when": "voting_disabled_or_failed"
    }
  }
}
```

### Ejemplo de Flujo de Votaci√≥n Simple
```
Usuario: "Enciende la luz del sal√≥n"

LLM-A Voto: "ACCI√ìN: encender_luz, ENTIDADES: {lugar: 'sal√≥n'}, CONFIANZA: 0.9"
LLM-B Voto: "ACCI√ìN: encender_luz, ENTIDADES: {lugar: 'sal√≥n'}, CONFIANZA: 0.85" 
LLM-C Voto: "ACCI√ìN: encender_luz, ENTIDADES: {lugar: 'sal√≥n'}, CONFIANZA: 0.8"

CONSENSO: encender_luz (3/3 votos) ‚Üí EJECUTAR ACCI√ìN MCP
```

### Ejemplo de Descomposici√≥n Din√°mica por LLM
```
Usuario: "Consulta el tiempo de Madrid y programa una alarma si va a llover"

PASO 1 - AN√ÅLISIS LLM:
LLM Prompt: "Analiza esta petici√≥n y lista las acciones MCP necesarias: 'Consulta el tiempo de Madrid y programa una alarma si va a llover'"

LLM Response: {
  "subtasks": [
    {
      "action": "consultar_tiempo",
      "entities": {"ubicacion": "Madrid"},
      "description": "Consultar informaci√≥n meteorol√≥gica de Madrid"
    },
    {
      "action": "programar_alarma_condicional", 
      "entities": {"condicion": "si_llueve", "ubicacion": "Madrid"},
      "description": "Programar alarma basada en condici√≥n meteorol√≥gica",
      "depends_on_result": "consultar_tiempo"
    }
  ]
}

PASO 2 - EJECUCI√ìN ORQUESTADA:
- Estado inicial: PENDING [consultar_tiempo, programar_alarma_condicional]
- Ejecuta: consultar_tiempo(Madrid) ‚Üí Resultado: "Lluvia probable 70%"  
- Estado: PENDING [programar_alarma_condicional], COMPLETED [consultar_tiempo]
- Ejecuta: programar_alarma_condicional(condicion="si_llueve") ‚Üí Resultado: "Alarma creada"
- Estado: COMPLETED [consultar_tiempo, programar_alarma_condicional]
- CONVERSACI√ìN COMPLETADA: "En Madrid hay 70% probabilidad de lluvia. He programado una alarma para avisarte."
```

### Configuraci√≥n de MCPs Disponibles (mcp_registry.json)
```json
{
  "available_mcps": {
    "consultar_tiempo": {
      "description": "Consulta informaci√≥n meteorol√≥gica de una ubicaci√≥n",
      "required_entities": ["ubicacion"],
      "service_endpoint": "weather-mcp-service"
    },
    "programar_alarma": {
      "description": "Programa una alarma para una fecha/hora espec√≠fica", 
      "required_entities": ["fecha_hora", "mensaje"],
      "service_endpoint": "system-mcp-service"
    },
    "programar_alarma_condicional": {
      "description": "Programa alarma basada en condiciones externas",
      "required_entities": ["condicion"],
      "service_endpoint": "system-mcp-service"
    },
    "crear_github_issue": {
      "description": "Crea un issue en un repositorio de GitHub",
      "required_entities": ["titulo", "descripcion"],
      "service_endpoint": "github-mcp-service"
    }
  }
}
```

### **üéØ OBJETIVO COMPLETO (Futuras Tareas)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Audio     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    JSON    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WHISPER-MS     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  GATEWAY-MS     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ INTENTMGR-V2    ‚îÇ
‚îÇ  (Transcripci√≥n)‚îÇ              ‚îÇ  (Routing)      ‚îÇ            ‚îÇ (LLM-RAG+MoE)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                          ‚îÇ
                                                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VECTOR STORE    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   RAG ENGINE    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  EXPERT ROUTER  ‚îÇ
‚îÇ (Embeddings)    ‚îÇ              ‚îÇ (Similarity)    ‚îÇ            ‚îÇ  (MoE Selection) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                          ‚îÇ
                                                                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     LLM-A       ‚îÇ              ‚îÇ     LLM-B       ‚îÇ    ‚îÇ     LLM-C       ‚îÇ
‚îÇ   (GPT-4)       ‚îÇ              ‚îÇ  (Claude-3)     ‚îÇ    ‚îÇ (GPT-3.5-Turbo) ‚îÇ
‚îÇ   "Voto: X"     ‚îÇ              ‚îÇ   "Voto: Y"     ‚îÇ    ‚îÇ   "Voto: Z"     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                                ‚îÇ                        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ CONSENSUS ENGINE‚îÇ
                ‚îÇ (Procesa votos) ‚îÇ
                ‚îÇ Decisi√≥n final  ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CONVERSATION    ‚îÇ              ‚îÇ   MCP ACTIONS   ‚îÇ    ‚îÇ   SINGLE LLM    ‚îÇ
‚îÇ   MANAGER       ‚îÇ              ‚îÇ (Taiga/Weather) ‚îÇ    ‚îÇ   (Fallback)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```